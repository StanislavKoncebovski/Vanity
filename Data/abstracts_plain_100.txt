Objective The overall research objective was to theoretically and empirically develop the ideas around a system of safety management practices (ten practices were elaborated), to test their relationship with objective safety statistics (such as accident rates), and to explore how these practices work to achieve positive safety results (accident prevention) through worker engagement. Method Data were collected using safety manager, supervisor and employee surveys designed to assess and link safety management system practices, employee perceptions resulting from existing practices, and safety performance outcomes. Results Results indicate the following: there is a significant negative relationship between the presence of ten individual safety management practices, as well as the composite of these practices, with accident rates; there is a significant negative relationship between the level of safety-focused worker emotional and cognitive engagement with accident rates; safety management systems and worker engagement levels can be used individually to predict accident rates; safety management systems can be used to predict worker engagement levels; and worker engagement levels act as mediators between the safety management system and safety performance outcomes (such as accident rates). Implications Even though the presence of safety management system practices is linked with incident reduction and may represent a necessary first-step in accident prevention, safety performance may also depend on mediation by safety-focused cognitive and emotional engagement by workers. Thus, when organizations invest in a safety management system approach to reducing/preventing accidents and improving safety performance, they should also be concerned about winning over the minds and hearts of their workers through human performance-based safety management systems designed to promote and enhance worker engagement. © 2013 The Authors.
The objective of an accident-mapping algorithm is to snap traffic accidents onto the correct road segments. Assigning accidents onto the correct segments facilitate to robustly carry out some key analyses in accident research including the identification of accident hot-spots, network-level risk mapping and segment-level accident risk modelling. Existing risk mapping algorithms have some severe limitations: (i) they are not easily 'transferable' as the algorithms are specific to given accident datasets; (ii) they do not perform well in all road-network environments such as in areas of dense road network; and (iii) the methods used do not perform well in addressing inaccuracies inherent in and type of road environment. The purpose of this paper is to develop a new accident mapping algorithm based on the common variables observed in most accident databases (e.g. road name and type, direction of vehicle movement before the accident and recorded accident location). The challenges here are to: (i) develop a method that takes into account uncertainties inherent to the recorded traffic accident data and the underlying digital road network data, (ii) accurately determine the type and proportion of inaccuracies, and (iii) develop a robust algorithm that can be adapted for any accident set and road network of varying complexity. In order to overcome these challenges, a distance based pattern-matching approach is used to identify the correct road segment. This is based on vectors containing feature values that are common in the accident data and the network data. Since each feature does not contribute equally towards the identification of the correct road segments, an ANN approach using the single-layer perceptron is used to assist in "learning" the relative importance of each feature in the distance calculation and hence the correct link identification. The performance of the developed algorithm was evaluated based on a reference accident dataset from the UK confirming that the accuracy is much better than other methods. © 2014 Published by Elsevier Ltd. All rights reserved.
The Driver Behavior Questionnaire (DBQ) is a self-report measure of driving behavior that has been widely used over more than 20 years. Despite this wealth of evidence a number of questions remain, including understanding the correlation between its violations and errors sub-components, identifying how these components are related to crash involvement, and testing whether a DBQ based on a reduced number of items can be effective. We address these issues using a bifactor modeling approach to data drawn from the UK Cohort II longitudinal study of novice drivers. This dataset provides observations on 12,012 drivers with DBQ data collected at.5, 1, 2 and 3 years after passing their test. A bifactor model, including a general factor onto which all items loaded, and specific factors for ordinary violations, aggressive violations, slips and errors fitted the data better than correlated factors and second-order factor structures. A model based on only 12 items replicated this structure and produced factor scores that were highly correlated with the full model. The ordinary violations and general factor were significant independent predictors of crash involvement at 6 months after starting independent driving. The discussion considers the role of the general and specific factors in crash involvement.
Operating a motor vehicle under the influence of alcohol (OUI) is an international problem. In the United States, one intervention strategy is to require offenders to attend group-delivered interventions. We compared three year rearrest rates among 12,267 individuals in Maine receiving either a motivation-enhancing (ME) program, Prime For Life®, or historical standard care (SC) programs. We created two cohorts, one when Maine used SC (9/1/1999-8/31/2000) and one after the ME program was implemented (9/1/2002-8/31/2003). Adjusted for control variables, rearrest rates among people not completing an assigned program did not differ for the ME versus SC cohorts (12.1% and 11.6%, respectively; OR = 1.05, ns). In contrast, ME compared to SC program completers had lower rearrest rates (7.4% versus 9.9%, OR = 0.73, p <.05). The same pattern occurred for people required to take these programs plus substance use treatment (12.1% versus 14.7%, OR = 0.82, p <.01). For those rearrested, time to rearrest did not differ between ME and SC cohorts. Among those required to have substance abuse treatment, ME and SC arrest rates did not differ for younger individuals; otherwise, the ME cohort's lower rearrest rates occurred across gender, age, having a previous OUI, and having completed a previous intervention program.
Driver drowsiness has been implicated as a major causal factor in road accidents. Tools that allow remote monitoring and management of driver fatigue are used in the mining and road transport industries. Increasing drivers' own awareness of their drowsiness levels using such tools may also reduce risk of accidents. The study examined the effects of real-time blink-velocity-derived drowsiness feedback on driver performance and levels of alertness in a military setting. A sample of 15 Army Reserve personnel (1 female) aged 21-59 (M = 41.3, SD = 11.1) volunteered to being monitored by an infra-red oculography-based Optalert Alertness Monitoring System (OAMS) while they performed their regular driving tasks, including on-duty tasks and commuting to and from duty, for a continuous period of 4-8 weeks. For approximately half that period, blink-velocity-derived Johns Drowsiness Scale (JDS) scores were fed back to the driver in a counterbalanced repeated-measures design, resulting in a total of 419 driving periods under "feedback" and 385 periods under "no-feedback" condition. Overall, the provision of real-time feedback resulted in reduced drowsiness (lower JDS scores) and improved alertness and driving performance ratings. The effect was small and varied across the 24-h circadian cycle but it remained robust after controlling for time of day and driving task duration. Both the number of JDS peaks counted for each trip and their duration declined in the presence of drowsiness feedback, indicating a dynamic pattern that is consistent with a genuine, entropy-reducing feedback mechanism (as distinct from random re-alerting) behind the observed effect. Its mechanisms and practical utility have yet to be fully explored. Direct examination of the alternative, random re-alerting explanation of this feedback effect is an important step for future research.
Identifying the changes in driving behavior that underlie the decrease in crash risk over the first few months of driving is key to efforts to reduce injury and fatality risk in novice drivers. This study represented a secondary data analysis of 1148 drivers who participated in the UK Cohort II study. The Driver Behavior Questionnaire was completed at 6 months and 1, 2 and 3 years after licensure. Linear latent growth models indicated significant increases across development in all four dimensions of aberrant driving behavior under scrutiny: aggressive violations, ordinary violations, errors and slips. Unconditional and conditional latent growth class analyses showed that the observed heterogeneity in individual trajectories was explained by the presence of multiple homogeneous groups of drivers, each exhibiting specific trajectories of aberrant driver behavior. Initial levels of aberrant driver behavior were important in identifying sub-groups of drivers. All classes showed positive slopes; there was no evidence of a group of drivers whose aberrant behavior decreased over time that might explain the decrease in crash involvement observed over this period. Male gender and younger age predicted membership of trajectories with higher levels of aberrant behavior. These findings highlight the importance of early intervention for improving road safety. We discuss the implications of our findings for understanding the behavioral underpinnings of the decrease in crash involvement observed in the early months of driving.
Public health surveillance programs in the U.S. are undergoing landmark changes with the availability of electronic health records and advancements in information technology. Injury narratives gathered from hospital records, workers compensation claims or national surveys can be very useful for identifying antecedents to injury or emerging risks. However, classifying narratives manually can become prohibitive for large datasets. The purpose of this study was to develop a human-machine system that could be relatively easily tailored to routinely and accurately classify injury narratives from large administrative databases such as workers compensation. We used a semi-automated approach based on two Naïve Bayesian algorithms to classify 15,000 workers compensation narratives into two-digit Bureau of Labor Statistics (BLS) event (leading to injury) codes. Narratives were filtered out for manual review if the algorithms disagreed or made weak predictions. This approach resulted in an overall accuracy of 87%, with consistently high positive predictive values across all two-digit BLS event categories including the very small categories (e.g., exposure to noise, needle sticks). The Naïve Bayes algorithms were able to identify and accurately machine code most narratives leaving only 32% (4853) for manual review. This strategy substantially reduces the need for resources compared with manual review alone.
Although speed is considered to be one of the main crash contributory factors, research findings are inconsistent. Independent of the robustness of their statistical approaches, crash frequency models typically employ crash data that are aggregated using spatial criteria (e.g., crash counts by link termed as a link-based approach). In this approach, the variability in crashes between links is explained by highly aggregated average measures that may be inappropriate, especially for time-varying variables such as speed and volume. This paper re-examines crash-speed relationships by creating a new crash data aggregation approach that enables improved representation of the road conditions just before crash occurrences. Crashes are aggregated according to the similarity of their pre-crash traffic and geometric conditions, forming an alternative crash count dataset termed as a condition-based approach. Crash-speed relationships are separately developed and compared for both approaches by employing the annual crashes that occurred on the Strategic Road Network of England in 2012. The datasets are modelled by injury severity using multivariate Poisson lognormal regression, with multivariate spatial effects for the link-based model, using a full Bayesian inference approach. The results of the condition-based approach show that high speeds trigger crash frequency. The outcome of the link-based model is the opposite; suggesting that the speed-crash relationship is negative regardless of crash severity. The differences between the results imply that data aggregation is a crucial, yet so far overlooked, methodological element of crash data analyses that may have direct impact on the modelling outcomes.
Background Successfully increasing cycling across a broad range of the population would confer important health benefits, but many potential cyclists are deterred by fears about traffic danger. Media coverage of road traffic crashes may reinforce this perception. As part of a wider effort to model the system dynamics of urban cycling, in this paper we examined how media coverage of cyclist fatalities in London changed across a period when the prevalence of cycling doubled. We compared this with changes in the coverage of motorcyclist fatalities as a control group. Methods Police records of traffic crashes (STATS19) were used to identify all cyclist and motorcyclist fatalities in London between 1992 and 2012. We searched electronic archives of London's largest local newspaper to identify relevant articles (January 1992-April 2014), and sought to identify which police-reported fatalities received any media coverage. We repeated this in three smaller English cities. Results Across the period when cycling trips doubled in London, the proportion of fatalities covered in the local media increased from 6% in 1992-1994 to 75% in 2010-2012. By contrast, the coverage of motorcyclist fatalities remained low (4% in 1992-1994 versus 5% in 2010-2012; p = 0.007 for interaction between mode and time period). Comparisons with other English cities suggested that the changes observed in London might not occur in smaller cities with lower absolute numbers of crashes, as in these settings fatalities are almost always covered regardless of mode share (79-100% coverage for both cyclist and motorcyclist fatalities). Conclusion In large cities, an increase in the popularity (and therefore 'newsworthiness') of cycling may increase the propensity of the media to cover cyclist fatalities. This has the potential to give the public the impression that cycling has become more dangerous, and thereby initiate a negative feedback loop that dampens down further increases in cycling. Understanding these complex roles of the media in shaping cycling trends may help identify effective policy levers to achieve sustained growth in cycling.
Purpose To evaluate if attendance at Lifeskills, a safety education centre for children in Year 6 (10-11 years), is associated with engagement in safer behaviours, and with fewer accidents and injuries, in adolescence. Methods The sample are participants in the Avon Longitudinal Study of Parents and Children who attended school in the Lifeskills catchment area in Year 6; 60% attended Lifeskills. At 14-15 years, participants (n approximately 3000, varies by outcome) self-reported road safety behaviours and accidents, and perceived health effects and use of alcohol, cannabis, and tobacco. Additional outcomes from linkage to Hospital Episodes Statistics were available for a sub-sample (n = 1768): hospital admittance (for accident-related reason, from 11-16 years) and A&E attendance (for any reason, from approximately 14-16 years). Results Children who attended Lifeskills were more likely to report using pedestrian crossings on their way to school than children who did not attend (59% versus 52%). Lifeskills attendance was unrelated to the ownership of cycle helmets, or the use of cycle helmets, seat belts, or reflective/fluorescent clothing, or to A&E attendance. Use of cycle helmets (37%) and reflective/fluorescent clothing (<4%) on last cycle was low irrespective of Lifeskills attendance. Lifeskills attendance was associated with less reported smoking and cannabis use, but was generally unrelated to perceptions of the health impact of substance use. Conclusions Lifeskills attendance was associated with some safer behaviours in adolescence. The overall low use of cycle helmets and reflective/fluorescent clothing evidences the need for powerful promotion of some safer behaviours at Lifeskills and at follow-up in schools.
Motivated by the thousands of pedestrians killed each year in train impacts, this paper investigates the life-saving capability of four high-level locomotive bumper concepts. The head motions produced by the four concepts are modeled as one or two square acceleration pulses and are analyzed using the Head Injury Criterion (HIC). Surprisingly, the analyses show that all four concepts can achieve HIC values of less than 200 for an impact with a locomotive traveling at 100 km/h. Two of the concepts eject the pedestrian trackside with at a velocity of roughly 40 km/h and the risk of ground-impact injury is discussed in the context of related automobile accident data. The computed bumper lengths are a fraction of the overall length of a locomotive and are thus feasible for practical implementation. One concept involves an oblique impact and the potential for rotational head injury is analyzed. This basic feasibility research motivates future investigations into the detailed design of bumper shapes, multi-body pedestrian simulations, and finite-element injury models.
Research has shown that safety climate is among the strongest predictors of safety behavior and safety outcomes in a variety of settings. Previous studies have established that safety climate is a multi-faceted construct referencing multiple levels of management within a company, most generally: the organization level (employee perceptions of top management's commitment to and prioritization of safety) and group level (employee perceptions of direct supervisor's commitment to and prioritization of safety). Yet, no research to date has examined the potential interaction between employees’ organization-level safety climate (OSC) and group-level safety climate (GSC) perceptions. Furthermore, prior research has mainly focused on traditional work environments in which supervisors and workers interact in the same location throughout the day. Little research has been done to examine safety climate with regard to lone workers. The present study aims to address these gaps by examining the relationships between truck drivers’ (as an example of lone workers) perceptions of OSC and GSC, both potential linear and non-linear relationships, and how these predict important safety outcomes. Participants were 8095 truck drivers from eight trucking companies in the United States with an average response rate of 44.8%. Results showed that employees’ OSC and GSC perceptions are highly correlated (r =  0.78), but notable gaps between the two were observed for some truck drivers. Uniquely, both OSC and GSC scores were found to have curvilinear relationships with safe driving behavior, and both scores were equally predictive of safe driving behavior. Results also showed the two levels of climate significantly interacted with one another to predict safety behavior such that if either the OSC or GSC scores were low, the other's contribution to safety behavior became stronger. These findings suggest that OSC and GSC may function in a compensatory manner and promote safe driving behavior even when either OSC or GSC scores are low. The results of this study provide critical insight into the supplementary interaction between perceptions of OSC and GSC. Recommendations for future research, as well as practical recommendations for organizational intervention, are discussed.
Injury narratives are now available real time and include useful information for injury surveillance and prevention. However, manual classification of the cause or events leading to injury found in large batches of narratives, such as workers compensation claims databases, can be prohibitive. In this study we compare the utility of four machine learning algorithms (Naïve Bayes, Single word and Bi-gram models, Support Vector Machine and Logistic Regression) for classifying narratives into Bureau of Labor Statistics Occupational Injury and Illness event leading to injury classifications for a large workers compensation database. These algorithms are known to do well classifying narrative text and are fairly easy to implement with off-the-shelf software packages such as Python. We propose human-machine learning ensemble approaches which maximize the power and accuracy of the algorithms for machine-assigned codes and allow for strategic filtering of rare, emerging or ambiguous narratives for manual review. We compare human-machine approaches based on filtering on the prediction strength of the classifier vs. agreement between algorithms. Regularized Logistic Regression (LR) was the best performing algorithm alone. Using this algorithm and filtering out the bottom 30% of predictions for manual review resulted in high accuracy (overall sensitivity/positive predictive value of 0.89) of the final machine-human coded dataset. The best pairings of algorithms included Naïve Bayes with Support Vector Machine whereby the triple ensemble NBSW = NBBI-GRAM = SVM had very high performance (0.93 overall sensitivity/positive predictive value and high accuracy (i.e. high sensitivity and positive predictive values)) across both large and small categories leaving 41% of the narratives for manual review. Integrating LR into this ensemble mix improved performance only slightly. For large administrative datasets we propose incorporation of methods based on human-machine pairings such as we have done here, utilizing readily-available off-the-shelf machine learning techniques and resulting in only a fraction of narratives that require manual review. Human-machine ensemble methods are likely to improve performance over total manual coding.
Objective Given the aging U.S. population and resulting number of older drivers in the coming years, it is important to understand the factors leading to their involvement in vehicle crashes and develop counter-measures to reduce their frequency and severity. This is also useful for helping older adults “age in place” in terms of accessibility, mobility, quality of life and safety. Thus, the objective of this study was to provide up-to-date data on differences in age-related risks and rates for involvement in fatal intersection motor-vehicle crashes in the US. Methods Pooled data for the years 2011–2014 from the FARS, a census of fatal traffic crashes within the 50 States, the District of Columbia, and Puerto Rico, created by the US National Highway Traffic Safety Administration (NHTSA) were used to calculate summary statistics including annualized crash rates. Multivariate logistic regression models were used to evaluate age and gender-related differences in fatal intersection crash risk, controlling for covariates. An induced exposure analysis was conducted to calculate crash involvement ratios (CIRs) for all two-vehicle fatal intersection crashes. Older and younger drivers were compared with respect to the presence of factors related to intersection crashes using a multivariate Poisson regression model. Results During the period of 2011–2014, among the reported 120,809 fatal accidents in the US involving 178,489 drivers of vehicles, 48,733 (28%) were drivers involved in fatal intersection crashes. Age-adjusted annualized fatal intersection crash rates per 100,000 licensed drivers were highest for drivers aged 85 or older (9.89/100,000), followed by 20 years of age (8.93/100,000). Teen and older drivers (55+ years of age) were over-involved in fatal intersection crashes, drivers from 20 to 54 years old were under-involved. Male and female drivers, 70–74 years of age, were 20% and 21%, respectively, more likely to be involved in a fatal intersection crash than 20–24 year olds (of same gender). By age 85, fatal intersection crash risk for all drivers was almost doubled. Significant differences in factors related to crashes involving younger ( < 65) and older (65+ years) drivers were time of day, lighting and weather conditions, day of week, roadway type and number of lanes, presence of visible traffic controls, speed limit and estimated driving speed, and whether the driver was deemed at fault for the crash Conclusion The results provide the most up-to-date analysis of aging and fatal intersection crash risk in the US, and underscore several trends worthy of further investigation. Older adults face a number of challenges associated with natural aging, including sensory, perceptual, cognitive and motor declines that may impact their driving. As with younger drivers, expanded or renewed approaches to driver training at licensing renewals, as well as safety-based technological advances are viable avenues toward improving the safety outlook for older adults.
In this paper, we propose a Bayesian hierarchical model for predicting accident counts in future years at sites within a pool of potential road safety hotspots. The aim is to inform road safety practitioners of the location of likely future hotspots to enable a proactive, rather than reactive, approach to road safety scheme implementation. A feature of our model is the ability to rank sites according to their potential to exceed, in some future time period, a threshold accident count which may be used as a criterion for scheme implementation. Our model specification enables the classical empirical Bayes formulation – commonly used in before-and-after studies, wherein accident counts from a single before period are used to estimate counterfactual counts in the after period – to be extended to incorporate counts from multiple time periods. This allows site-specific variations in historical accident counts (e.g. locally-observed trends) to offset estimates of safety generated by a global accident prediction model (APM), which itself is used to help account for the effects of global trend and regression-to-mean (RTM). The Bayesian posterior predictive distribution is exploited to formulate predictions and to properly quantify our uncertainty in these predictions. The main contributions of our model include (i) the ability to allow accident counts from multiple time-points to inform predictions, with counts in more recent years lending more weight to predictions than counts from time-points further in the past; (ii) where appropriate, the ability to offset global estimates of trend by variations in accident counts observed locally, at a site-specific level; and (iii) the ability to account for unknown/unobserved site-specific factors which may affect accident counts. We illustrate our model with an application to accident counts at 734 potential hotspots in the German city of Halle; we also propose some simple diagnostics to validate the predictive capability of our model. We conclude that our model accurately predicts future accident counts, with point estimates from the predictive distribution matching observed counts extremely well.
Zohar and Luria's (2005) safety climate (SC) scale, measuring organization- and group- level SC each with 16 items, is widely used in research and practice. To improve the utility of the SC scale, we shortened the original full-length SC scales. Item response theory (IRT) analysis was conducted using a sample of 29,179 frontline workers from various industries. Based on graded response models, we shortened the original scales in two ways: (1) selecting items with above-average discriminating ability (i.e. offering more than 6.25% of the original total scale information), resulting in 8-item organization-level and 11-item group-level SC scales; and (2) selecting the most informative items that together retain at least 30% of original scale information, resulting in 4-item organization-level and 4-item group-level SC scales. All four shortened scales had acceptable reliability (≥0.89) and high correlations (≥0.95) with the original scale scores. The shortened scales will be valuable for academic research and practical survey implementation in improving occupational safety.
We investigated after effects of automation in take-over scenarios in a high-end moving-base driving simulator. Drivers performed evasive manoeuvres encountering a blocked lane in highway driving. We compared the performance of drivers 1) during manual driving, 2) after automated driving with eyes on the road while performing the cognitively demanding n-back task, and 3) after automated driving with eyes off the road performing the visually demanding SuRT task. Both minimum time to collision (TTC) and minimum clearance towards the obstacle disclosed a substantial number of near miss events and are regarded as valuable surrogate safety metrics in evasive manoeuvres. TTC proved highly sensitive to the applied definition of colliding paths, and we prefer robust solutions using lane position while disregarding heading. The extended time to collision (ETTC) which takes into account acceleration was close to the more robust conventional TTC. In line with other publications, the initial steering or braking intervention was delayed after using automation compared to manual driving. This resulted in lower TTC values and stronger steering and braking actions. Using automation, effects of cognitive distraction were similar to visual distraction for the intervention time with effects on the surrogate safety metric TTC being larger with visual distraction. However the precision of the evasive manoeuvres was hardly affected with a similar clearance towards the obstacle, similar overshoots and similar excursions to the hard shoulder. Further research is needed to validate and complement the current simulator based results with human behaviour in real world driving conditions. Experiments with real vehicles can disclose possible systematic differences in behaviour, and naturalistic data can serve to validate surrogate safety measures like TTC and obstacle clearance in evasive manoeuvres.
Background Much of the driver distraction and inattention work to date has focused on concerns over drivers removing their eyes from the forward roadway to perform non-driving-related tasks, and its demonstrable link to safety consequences when these glances are timed at inopportune moments. This extensive literature has established, through the analyses of glance from naturalistic datasets, a clear relationship between eyes-off-road, lead vehicle closing kinematics, and near-crash/crash involvement. Objective This paper looks at the role of driver expectation in influencing drivers’ decisions about when and for how long to remove their eyes from the forward roadway in an analysis that consider the combined role of on- and off-road glances. Method Using glance data collected in the 100-Car Naturalistic Driving Study (NDS), near-crashes were examined separately from crashes to examine how momentary differences in glance allocation over the 25-s prior to a precipitating event can differentiate between these two distinct outcomes. Individual glance metrics of mean single glance duration (MSGD), total glance time (TGT), and glance count for off-road and on-road glance locations were analyzed. Output from the AttenD algorithm (Kircher and Ahlström, 2009) was also analyzed as a hybrid measure; in threading together on- and off-road glances over time, its output produces a pattern of glance behavior meaningful for examining attentional effects. Results Individual glance metrics calculated at the epoch-level and binned by 10-s units of time across the available epoch lengths revealed that drivers in near-crashes have significantly longer on-road glances, and look less frequently between on- and off- road locations in the moments preceding a precipitating event as compared to crashes. During on-road glances, drivers in near-crashes were found to more frequently sample peripheral regions of the roadway than drivers in crashes. Output from the AttenD algorithm affirmed the cumulative net benefit of longer on-road glances and of improved attention management between on- and off-road locations. Conclusion The finding of longer on-road glances differentiating between safety-critical outcomes in the 100-Car NDS data underscores the importance of attention management in how drivers look both on and off the road. It is in the pattern of glances to and from the forward roadway that drivers obtained critical information necessary to inform their expectation of hazard potential to avoid a crash. Application This work may have important implications for attention management in the context of the increasing prevalence of in-vehicle demands as well as of vehicle automation.
Previous research suggests darkness increases the risk of a collision involving a pedestrian and the severity of any injury suffered. Pedestrian crossings are intended to make it safer to cross the road, but it is not clear whether they are effective at doing this after-dark, compared with during daylight. Biannual clock changes resulting from transitions to and from daylight saving time were used to compare RTCs in the UK during daylight and darkness but at the same time of day, thus controlling for potential influences on RTC numbers not related to the ambient light condition. Odds ratios and regression discontinuity analysis suggested there was a significantly greater risk of a pedestrian RTC at a crossing after-dark than during daylight. Results also suggested the risk of an RTC after-dark was greater at a pedestrian crossing than at a location at least 50 m away from a crossing. Whilst these results show the increased danger to pedestrians using a designated crossing after-dark, this increased risk is not due to a lack of lighting at these locations as 98% of RTCs at pedestrian crossings after-dark were lit by road lighting. This raises questions about the adequacy and effectiveness of the lighting used at pedestrian crossings.
Passenger modes in India include walking, cycling, buses, trains, intermediate public transport modes (IPT) such as three-wheeled auto rickshaws or tuk-tuks, motorised two-wheelers (2W) as well as cars. However, epidemiological studies of traffic crashes in India have been limited in their approach to account for the exposure of these road users. In 2011, for the first time, census in India reported travel distance and mode of travel for workers. A Poisson-lognormal mixture regression model is developed at the state level to explore the relationship of road deaths of all the road users with commute travel distance by different on-road modes. The model controlled for diesel consumption (proxy for freight traffic), length of national highways, proportion of population in urban areas, and built-up population density. The results show that walking, cycling and, interestingly, IPT are associated with lower risk of road deaths, while 2W, car and bus are associated with higher risk. Promotion of IPT has twofold benefits of increasing safety as well as providing a sustainable mode of transport. The mode shift scenarios show that, for similar mode shift across the states, the resulting trends in road deaths are highly dependent on the baseline mode shares. The most worrying trend is the steep growth of death burden resulting from mode shift of walking and cycling to 2W. While the paper illustrates a limited set of mode shift scenarios involving two modes at a time, the model can be applied to assess safety impacts resulting from a more complex set of scenarios.
What are the main contributing factors to road accidents? Factors such as inexperience, lack of skill, and risk-taking behaviors have been associated with the collisions of young drivers. In contrast, visual, cognitive, and mobility impairment have been associated with the collisions of older drivers. We investigated the main causes of road accidents by drawing on multiple sources: expert views of police officers, lay views of the driving public, and official road accident records. In Studies 1 and 2, police officers and the public were asked about the typical causes of road traffic collisions using hypothetical accident scenarios. In Study 3, we investigated whether the views of police officers and the public about accident causation influence their recall accuracy for factors reported to contribute to hypothetical road accidents. The results show that both expert views of police officers and lay views of the driving public closely approximated the typical factors associated with the collisions of young and older drivers, as determined from official accident records. The results also reveal potential underreporting of factors in existing accident records, identifying possible inadequacies in law enforcement practices for investigating driver distraction, drug and alcohol impairment, and uncorrected or defective eyesight. Our investigation also highlights a need for accident report forms to be continuously reviewed and updated to ensure that contributing factor lists reflect the full range of factors that contribute to road accidents. Finally, the views held by police officers and the public on accident causation influenced their memory recall of factors involved in hypothetical scenarios. These findings indicate that delay in completing accident report forms should be minimised, possibly by use of mobile reporting devices at the accident scene.
Cycling injury risk is an important topic, but few studies explore cycling risk in relation to exposure. This is largely because of a lack of exposure data, in other words how much cycling is done at different locations. This paper helps to fill this gap. It reports a case-control study of cycling injuries in London in 2013–2014, using modelled cyclist flow data alongside datasets covering some characteristics of the London route network. A multilevel binary logistic regression model is used to investigate factors associated with injury risk, comparing injury sites with control sites selected using the modelled flow data. Findings provide support for 'safety in numbers’: for each increase of a natural logarithmic unit (2.71828) in cycling flows, an 18% decrease in injury odds was found. Conversely, increased motor traffic volume is associated with higher odds of cycling injury, with one logarithmic unit increase associated with a 31% increase in injury odds. Twenty-mile per hour compared with 30mph speed limits were associated with 21% lower injury odds. Residential streets were associated with reduced injury odds, and junctions with substantially higher injury odds. Bus lanes do not affect injury odds once other factors are controlled for. These data suggest that speed limits of 20 mph may reduce cycling injury risk, as may motor traffic reduction. Further, building cycle routes that generate new cycle trips should generate 'safety in numbers’ benefits.
Drivers are at high crash risk when they begin independent driving, with liability decreasing steeply over the first three months. Their behavioural development, and other changes underlying improved safety are not well understood. We adopted an innovative longitudinal qualitative design, with thirteen newly qualified drivers completing a total of 36 semi-structured interviews, one, two and three months after acquiring a full UK driving license. The interviews probed high-risk factors for new drivers, as well as allowing space for generating novel road safety issues. Analysis adopted a dual deductive and inductive interpretative thematic approach, identifying three super-ordinate themes: (1) Improvements in car control skills and situation awareness; (2) A reduction in the thrill of taking risks when driving against a background of generally increasing driving speed; (3) Early concerns about their social status in the eyes of other road users during the early stages of driving, which may put pressure on them to drive faster than they felt comfortable with. The study provides important new leads towards understanding how novice driving becomes safer over the first few months of driving, including how well-studied concepts of driving skill and style may change during development of independent driving, and bringing the less rigorously studied concept of social status into focus.
Motorcyclists are involved in a disproportionate number of crashes given the distance they travel, with a high proportion of these crashes occurring at junctions. Despite car drivers being solely responsible for many road crashes involving a motorcycle, previous research has mostly focussed on understanding motorcyclists’ attitudes towards their own safety. We compared car drivers’ (n = 102) and motorcyclists’ (n = 579) opinions about junction crashes using a web-based questionnaire. Motorcyclists and car drivers were recruited in similar ways so that responses could be directly compared, accessing respondents through driver/rider forums and on social media. Car drivers’ and motorcyclists’ opinions were compared in relation to who they believe to be blameworthy in situations which varied in specificity, ranging from what road user they believe is most likely to cause a motorcyclist to have a road crash, to what road user is at fault in four specific scenarios involving a car and motorcycle at a junction. Two of these scenarios represented typical ‘Right of way’ (ROW) crashes with a motorcycle approaching from the left and right, and two scenarios involved a motorcycle overtaking another vehicle at the junction, known as ‘Motorcycle Manoeuvrability Accidents’ (MMA). Qualitative responses were analysed using LIWC software to detect objective differences in car drivers’ and motorcyclists’ language. Car drivers’ and motorcyclists’ opinions about the blameworthiness of accidents changed depending on how specific the situation was that was being presented. When respondents were asked about the cause of motorcycle crashes in a general abstract sense, car drivers’ and motorcyclists’ responses significantly differed, with motorcyclists more likely to blame car drivers, demonstrating an in-group bias. However, this in-group favouritism was reduced when asked about specific scenarios, especially in MMA situations which involve motorcyclists manoeuvring their motorcycles around cars at a junction. In the four specific scenarios, car drivers were more likely to blame the car driver, and motorcyclists were more likely to blame the motorcyclist. In the typical ROW scenarios, the responses given by both road users, as analysed by the LIWC, show that the law is taken into account, as well as a large emphasis on the lack of observation given around junctions, especially from car drivers. It is concluded that the perception of blameworthiness in crashes is very much dependent on the details of the crash, with a more specific situation eliciting a fairer evaluation by both car drivers and motorcyclists.
 Background: A novel bicycle helmet concept has been developed to mitigate rotational head acceleration, which is a predominant mechanism of traumatic brain injury (TBI). This WAVECEL concept employs a collapsible cellular structure that is recessed within the helmet to provide a rotational suspension. This cellular concept differs from other bicycle helmet technologies for mitigation of rotational head acceleration, such as the commercially available Multi-Directional Impact Protection System (MIPS) technology which employs a slip liner to permit sliding between the helmet and the head during impact. This study quantified the efficacy of both, the WAVECEL cellular concept, and a MIPS helmet, in direct comparison to a traditional bicycle helmet made of rigid expanded polystyrene (EPS). Methods: Three bicycle helmet types were subjected to oblique impacts in guided vertical drop tests onto an angled anvil: traditional EPS helmets (CONTROL group); helmets with a MIPS slip liner (SLIP group); and helmets with a WAVECEL cellular structure (CELL group). Helmet performance was evaluated using 4.8 m/s impacts onto anvils angled at 30° 45° and 60° from the horizontal plane. In addition, helmet performance was tested at a faster speed of 6.2 m/s onto the 45° anvil. Five helmets were tested under each of the four impact conditions for each of the three groups, requiring a total of 60 helmets. Headform kinematics were acquired and used to calculate an injury risk criterion for Abbreviated Injury Score (AIS) 2 brain injury. Results: Linear acceleration of the headform remained below 90 g and was not associated with the risk of skull fracture in any impact scenario and helmet type. Headform rotational acceleration in the CONTROL group was highest for 6.2 m/s impacts onto the 45° anvil (7.2 ± 0.6 krad/s 2 ). In this impact scenario, SLIP helmets and CELL helmets reduced rotational acceleration by 22% (p = 0003) and 73% (p < 0.001), respectively, compared to CONTROL helmets. The CONTROL group had the highest AIS 2 brain injury risk of 59 ± 8% for 6.2 m/s impacts onto the 45° anvil. In this impact scenario, SLIP helmets and CELL helmets reduced the AIS 2 brain injury risk to 34.2% (p = 0.001) and 1.2% (p < 0.001), respectively, compared to CONTROL helmets. Discussion: Results of this study are limited to a narrow range of impact conditions, but demonstrated the potential that rotational acceleration and the associated brain injury risk can be significantly reduced by the cellular WAVECEL concept or a MIPS slip liner. Results obtained under specific impact angles and impact velocities indicated performance differences between these mechanisms. These differences emphasize the need for continued research and development efforts toward helmet technologies that further improve protection from brain injury over a wide range a realistic impact parameters. 
Objective: A remarkable portion of children's traffic-related deaths occurred when travelling in as passengers in vehicles, but so far, few studies have focused on crash characteristics and crash risks of drivers with child passengers. It has been assumed that drivers with child passengers drive responsibly, but on the contrary, children in vehicles can distract drivers, increasing crash risks. In this study, we examined fatal crash characteristics and fatal crash risks of drivers with child passengers. Methods: Fatal crash data from the U.S. Fatality Analysis Reporting System (FARS) for 1996–2015 were used. Only passenger-vehicle drivers aged 23–46 years old were included in the analysis because they represent the typical age of drivers with 0–9-year-old child passengers in the database. Prevalence of crash characteristics and the odds of being at fault were examined for drivers with only child passengers and compared to drivers with only adult passengers, with no passengers and with both adult and child passengers. Analyses were done separately for intersection crashes and non-junction crashes. Results: Female drivers were involved in twice as many fatal crashes alone with child passengers compared to male drivers. Drivers with only child passengers were more often reported as being inattentive, but for them, risk-taking behaviours were less typical than for drivers without child passengers. Our results showed that these differences were more evident in non-junction crashes than in intersection crashes. When risk-taking behaviours were controlled, both male and female drivers with only child passengers had higher odds of being at fault than drivers with adult passengers (with or without children) in non-junction crashes, but these differences were not significant in intersection crashes. Conclusions: Drivers with child passengers represent a specific driver population. They have a higher tendency to engage in distractions while driving, but they have fewer risk-taking behaviour-related fatal crashes compared to drivers with no child passengers. Our results indicate that the effects of child-passenger-related distractions on fatal crash risks are more relevant outside intersections, presumably because drivers may try to self-regulate their interactions with child passengers and focus on driving in more demanding traffic situations.
Distraction and inattention pose a considerable threat to road safety, not only for car drivers, but also for vulnerable road users. Previous studies show that inattention and distraction are more often contributing factors in severe crashes, compared to less severe crashes. The correlation with severity appears to vary with the type of inattention. The aim of the present study was to conduct a comprehensive mapping of the types of inattention that contribute to fatal road crashes. This was done by exploring data from in-depth investigations of all fatal road crashes in Norway between 2011 and 2015 conducted by crash investigation teams of the Norwegian Public Roads Administration. Crash reports were selected for screening, based on codes indicating inattention as a possible contributing factor. Inattention among at-fault drivers of motor vehicles was found to contribute to almost one out of three fatal road crashes between 2011 and 2015. About one-third of inattention-related crashes involved pedestrians who were hit by motor vehicles, where the driver typically detected the pedestrian too late. Failure to check for information in blind spots or behind other sight obstructions is a typical form of inattention. Distraction by use of mobile phones contributed to between two and four percent of all fatal crashes, while other sources of distraction, within or outside of the vehicle, contributed to about ten percent. Driver inattention may be preventable by a system-oriented approach including a combination of vehicle technology, road and road environment improvements, appropriate signs and markings, education and information, as well as legal measures and enforcement regarding use of mobile phones, in-vehicle sight obstructions, and involvement in other secondary tasks during driving.
Novice drivers are statistically over-represented in reported road crashes, with recent evidence suggesting that some of this increased crash involvement may be a result of limitations in their cognitive processing. Such processing has typically been measured by recording drivers’ patterns of eye movements, however, the exact ways in which eye movements are reported and interpreted varies substantially between different studies in the literature. Therefore, the objective of this systematic review was to investigate whether novice drivers and experienced drivers do differ in clear and reproducible ways in their visual search. Studies were identified through searches of Web of Science, Medline, TRID Database, and the TRB Research in Progress Database, with no restrictions on publication status. Studies were included if they compared the visual search of a novice driver group (<3 years driving experience) and an experienced driver group (>3 years driving experience) using an eye tracking method and reported at least one of the following four visual search outcomes: fixation durations, horizontal spread of search, vertical spread of search and number of fixations. Two reviewers independently screened searches and assessed the full texts of potentially included studies. Of the 235 studies initially identified 18 were included in the review, with 13 studies reporting sufficient data to be included in the meta-analysis for at least one outcome measure. Given that the included studies deployed a range of method types, additional sub-group analyses were conducted using this factor. Sensitivity analyses were also conducted by temporarily removing extreme experience groups (e.g. driving instructors and learner drivers) in order to test the effect of different levels of experience and training. The meta-analyses, along with support from results discussed narratively, revealed that novice drivers have a narrower horizontal spread of search compared to experienced drivers, however, there were no overall differences in fixation durations, vertical spread of search or number of fixations when the studies were pooled together. These findings have important primary implications for the development of novice training interventions, with novice drivers needing to develop a broader horizontal spread of visual search, but not to necessarily learn to fixate further down the road. Subgroup analyses also provided considerations for future research studies in terms of the experience of the driver groups, and the method type used.
Worldwide, road crashes are a major course of death and serious injury. Police reports provide a rich source of data on the proximal causes (e.g., impairment by alcohol, failure to look properly) of road traffic collisions. Yet, road safety research has raised concerns about the quality and reliability of police reported data. In the UK crash report form, contributory factors are categorised (e.g., vehicle defects, driver error or reaction) to aid police officers in identifying appropriate factors. However, discord between the classification of contributory factors in crash reports and police officers’ own categorical perceptions may lead to misunderstanding, and in turn, misreporting of contributory factors. The current investigation recruited 162 police officers to report their perceptions of the relations among contributory factors in the UK crash report form. Hierarchical clustering analysis was used to identify an optimal category structure based on police officers’ perceptions. The clustering analysis identified a classification system with seven or eleven categories of contributory factors, maximising the internal coherence of categories and minimising discord with police officers’ perceptions. The findings also yield new insights into police officers’ perceptions of crash causation and demonstrate how statistical techniques can be used to inform the design of road traffic collision report forms.
For humans and other species, the ability to estimate the physical passage of time is of fundamental importance for perceptual, cognitive or motor functions. Despite this importance, any subjective estimation of temporal durations not only depends on the temporal dynamics of the to-be-timed stimulus or event, but also can be distorted by non-temporal perceptual, cognitive, and emotional effects. This study aimed to further explore critical stimulus characteristics modulating distracter-induced distortions in human time-reproduction. To this end, we investigated whether subjectively rated distracter dimensions of arousal and valence (related to levels of emotionality), or rather stimulus complexity, as a confounder, produce distortions in participants' reproduction of a previously trained target interval. Accuracy and precision of time-reproduction have been measured in distracter-trials, and compared to timing performance in baseline-trials without any distraction. Results showed temporal overproductions in a magnitude of less than distracter duration only for complex distracters. Most importantly, arousal level and valence of distracters were not accountable for temporal distortions. Within an internal clock framework, our pattern of results can best be interpreted in the context of attention-, rather than arousal-based mechanisms of timing. © 2013 The Authors.
Although there is increasing evidence to suggest that language is grounded in perception and action, the relationship between language and emotion is less well understood. We investigate the grounding of language in emotion using a novel approach that examines the relationship between the comprehension of a written discourse and the performance of affect-related motor actions (hand movements towards and away from the body). Results indicate that positively and negatively valenced words presented in context influence motor responses (Experiment 1), whilst valenced words presented in isolation do not (Experiment 3). Furthermore, whether discourse context indicates that an utterance should be interpreted literally or ironically can influence motor responding, suggesting that the grounding of language in emotional states can be influenced by discourse-level factors (Experiment 2). In addition, the finding of affect-related motor responses to certain forms of ironic language, but not to non-ironic control sentences, suggests that phrasing a message ironically may influence the emotional response that is elicited.
Perceiving one's causal control is important for adaptive behavior. Studying depression and other individual differences has provided insight into typical as well as pathological causal processing. We set out to study factors that have been shown to distinguish those with and without signs of depression and affect perceptions of causal control: levels of behavior, the availability of outcomes and learning about the environment or context. Two experiments were carried out in which participants, scoring low and high on the Beck Depression Inventory using established cutoffs, completed a causal control task, in which outcomes occurred with a low (25) or high probability (75). Behavior levels were either constrained (N1= 73) or unconstrained (N2= 74). Overall, findings showed that levels of behavior influenced people's experiences of the context in which events occurred. For all participants, very high behavior levels eliminated sensitivity to levels of outcomes occurring in the environment and lead to judgments that were consistent with conditional probabilities as opposed to the experimenter programmed contingency. Thus increased behavior increased perceived control via influence on context experience. This effect was also evident for those scoring high on the BDI. Overall conclusions are that behavior and context provide two important interlinked psychological pathways to perceived control. However, situations that constrain people's ability to respond freely can prevent people with signs of depression from taking control of a situation that would otherwise be uncontrollable.
The current study investigated the role of spatial distance in word learning. Two-year-old children saw three novel objects named while the objects were either in close proximity to each other or spatially separated. Children were then tested on their retention for the name-object associations. Keeping the objects spatially separated from each other during naming was associated with increased retention for children with larger vocabularies. Children with a lower vocabulary size demonstrated better retention if they saw objects in close proximity to each other during naming. This demonstrates that keeping a clear view of objects during naming improves word learning for children who have already learned many words, but keeping objects within close proximal range is better for children at earlier stages of vocabulary acquisition. The effect of distance is therefore not equal across varying vocabulary sizes. The influences of visual crowding, cognitive load, and vocabulary size on word learning are discussed.
The sense of agency refers to the feeling that we are in control of our actions and, through them, of events in the outside world. Much research has focused on the importance of retrospectively matching predicted and actual action outcomes for a strong sense of agency. Yet, recent studies have revealed that a metacognitive signal about the fluency of action selection can prospectively inform our sense of agency. Fluent, or easy, action selection leads to a stronger sense of agency over action outcomes than dysfluent, or difficult, selection. Since these studies used subliminal priming to manipulate action selection, it remained unclear whether supraliminal stimuli affecting action selection would have similar effects. We used supraliminal flankers to manipulate action selection in response to a central target. Experiment 1 revealed that conflict in action selection, induced by incongruent flankers and targets, led to reduced agency ratings over an outcome that followed the participant's response, relative to neutral and congruent flanking conditions. Experiment 2 replicated this result, and extended it to free choice between alternative actions. Finally, Experiment 3 varied the stimulus onset asynchrony (SOA) between flankers and target. Action selection performance varied with SOA. Agency ratings were always lower in incongruent than congruent trials, and this effect did not vary across SOAs. Sense of agency is influenced by a signal that tracks conflict in action selection, regardless of the visibility of stimuli inducing conflict, and even when the timing of the stimuli means that the conflict may not affect performance.
In the perception of target stimuli in rapid serial visual presentations, the process of temporal integration plays an important role when two targets are presented in direct succession (at Lag 1), causing them to be perceived as a singular episodic event. This has been associated with increased reversals of target order report and elevated task performance in classic paradigms. Yet, most current models of temporal attention do not incorporate a mechanism of temporal integration and it is currently an open question whether temporal integration is a factor in attentional processing: It might be an independent process, perhaps little more than a sensory sampling rate parameter, isolated to Lag 1, where it leaves the attentional dynamics otherwise unaffected. In the present study, these boundary conditions were tested. Temporal target integration was observed across sequences of three targets spanning an interval of 240 ms. Integration rates furthermore depended strongly on bottom-up attentional filtering, and to a lesser degree on top-down control. The results support the idea that temporal integration is an adaptive process that is part of, or at least interacts with, the attentional system. Implications for current models of temporal attention are discussed.
Previous findings suggest that older adults show impairments in the social perception of faces, including the perception of emotion and facial identity. The majority of this work has tended to examine performance on tasks involving young adult faces and prototypical emotions. While useful, this can influence performance differences between groups due to perceptual biases and limitations on task performance. Here we sought to examine how typical aging is associated with the perception of subtle changes in facial happiness and facial identity in older adult faces. We developed novel tasks that permitted the ability to assess facial happiness, facial identity, and non-social perception (object perception) across similar task parameters. We observe that aging is linked with declines in the ability to make fine-grained judgements in the perception of facial happiness and facial identity (from older adult faces), but not for non-social (object) perception. This pattern of results is discussed in relation to mechanisms that may contribute to declines in facial perceptual processing in older adulthood.
Cognates share their form and meaning across languages: “winter” in English means the same as “winter” in Dutch. Research has shown that bilinguals process cognates more quickly than words that exist in one language only (e.g. “ant” in English). This finding is taken as strong evidence for the claim that bilinguals have one integrated lexicon and that lexical access is language non-selective. Two English lexical decision experiments with Dutch–English bilinguals investigated whether the cognate facilitation effect is influenced by stimulus list composition. In Experiment 1, the ‘standard’ version, which included only cognates, English control words and regular non-words, showed significant cognate facilitation (31 ms). In contrast, the ‘mixed’ version, which also included interlingual homographs, pseudohomophones (instead of regular non-words) and Dutch-only words, showed a significantly different profile: a non-significant disadvantage for the cognates (8 ms). Experiment 2 examined the specific impact of these three additional stimuli types and found that only the inclusion of Dutch words significantly reduced the cognate facilitation effect. Additional exploratory analyses revealed that, when the preceding trial was a Dutch word, cognates were recognised up to 50 ms more slowly than English controls. We suggest that when participants must respond ‘no’ to non-target language words, competition arises between the ‘yes’- and ‘no’-responses associated with the two interpretations of a cognate, which (partially) cancels out the facilitation that is a result of the cognate's shared form and meaning. We conclude that the cognate facilitation effect is a real effect that originates in the lexicon, but that cognates can be subject to competition effects outside the lexicon.
Traditionally it has been thought that the overall organisation of categories in the brain is taxonomic. To examine this assumption, we had adults sort 140–150 diverse, familiar objects from different basic-level categories. Almost all the participants (80/81) sorted the objects more thematically than taxonomically. Sorting was only weakly modulated by taxonomic priming, and people still produced many thematically structured clusters when explicitly instructed to sort taxonomically. The first clusters that people produced were rated as having equal taxonomic and thematic structure. However, later clusters were rated as being increasingly thematically organised. A minority of items were consistently clustered taxonomically, but the overall dominance of thematically structured clusters suggests that people know more thematic than taxonomic relations among everyday objects. A final study showed that the semantic relations used to sort a given item in the initial studies predicted the proportion of thematic to taxonomic word associates generated to that item. However, unlike the results of the sorting task, most of these single word associates were related taxonomically. This latter difference between the results of large-scale, free sorting tasks versus single word association tasks suggests that thematic relations may be more numerous, but weaker, than taxonomic associations in our stored conceptual network. Novel statistical and numerical methods for objectively measuring sorting consistency were developed during the course of this investigation, and have been made publicly available.
Evidence shows that there are individual differences in the extent to which people attend to and integrate information into their decisions about the predictive contingencies between events and outcomes. In particular, information about the absence of events or outcomes, presented outside the current task frame, is often neglected. This trend is particularly evident in depression, as well as other psychopathologies, though reasons for information neglect remain unclear. We investigated this phenomenon across two experiments (Experiment 1: N = 157; Experiment 2: N = 150) in which participants, scoring low and high in the Beck Depression Inventory, were asked to learn a simple predictive relationship between a visual cue and an auditory outcome. We manipulated whether or not participants had prior experience of the visual cue outside of the task frame, whether such experience took place in the same or different context to the learning task, and the nature of the action required to signal occurrence of the auditory outcome. We found that all participants were capable of including extra-task experience into their assessment of the predictive cue-outcome relationship in whatever context it occurred. However, for mildly depressed participants, adjacent behaviours and similarity between the extra-task experience and the main task, influenced information integration, with patterns of ‘over-integration’ evident, rather than neglect as we had expected. Findings are suggestive of over-generalised experience on the part of mildly depressed participants.
Assessing facial attractiveness is a ubiquitous, inherent, and hard-wired phenomenon in everyday interactions. As such, it has highly adapted to the default way that faces are typically processed: viewing faces in upright orientation. By inverting faces, we can disrupt this default mode, and study how facial attractiveness is assessed. Faces, rotated at 90 (tilting to either side) and 180°, were rated on attractiveness and distinctiveness scales. For both orientations, we found that faces were rated more attractive and less distinctive than upright faces. Importantly, these effects were more pronounced for faces rated low in upright orientation, and smaller for highly attractive faces. In other words, the less attractive a face was, the more it gained in attractiveness by inversion or rotation. Based on these findings, we argue that facial attractiveness assessments might not rely on the presence of attractive facial characteristics, but on the absence of distinctive, unattractive characteristics. These unattractive characteristics are potentially weighed against an individual, attractive prototype in assessing facial attractiveness.
As agents seeking to learn how to successfully navigate their environments, humans can both obtain knowledge through direct experience, and second-hand through communicated beliefs. Questions remain concerning how communicated belief (or instruction) interacts with first-hand evidence integration, and how the former can bias the latter. Previous research has revealed that people are more inclined to seek out confirming evidence when they are motivated to uphold the belief, resulting in confirmation bias. The current research explores whether merely communicated beliefs affect evidence integration over time when it is not of interest to uphold the belief, and all evidence is readily available. In a novel series of on-line experiments, participants chose on each trial which of two options to play for money, being exposed to outcomes of both. Prior to this, they were exposed to favourable communicated beliefs regarding one of two options. Beliefs were either initially supported or undermined by subsequent probabilistic evidence (probabilities reversed halfway through the task, rendering the options equally profitable overall). Results showed that while communicated beliefs predicted initial choices, they only biased subsequent choices when supported by initial evidence in the first phase of the experiment. Findings were replicated across contexts, evidence sequence lengths, and probabilistic distributions. This suggests that merely communicated beliefs can prevail even when not supported by long run evidence, and in the absence of a motivation to uphold them. The implications of the interaction between communicated beliefs and initial evidence for areas including instruction effects, impression formation, and placebo effects are discussed.
Learning a new motor skill typically requires converting actions observed from a third-person perspective into fluid motor commands executed from a first-person perspective. In the present study, we test the hypothesis that during motor learning, the ability to discriminate between actions that have been observed and actions that have been executed is associated with learning aptitude, as assessed by a general measure of physical performance. Using a multi-day dance-training paradigm with a group of dance-naïve participants, we investigated whether actions that had been regularly observed could be discriminated from similar actions that had been physically practised over the course of three days, or a further set of similar actions that remained untrained. Training gains and performance scores at test were correlated with participants’ ability to discriminate between observed and practised actions, suggesting that an individual's ability to differentiate between visual versus visuomotor action encoding is associated with general motor learning.
Despite widespread use in clinical and experimental contexts, debate continues over whether or not the Sustained Attention to Response Task (SART) successfully measures sustained attention. Altering physical aspects of the response movement required to SART stimuli may help identify whether performance is a better measure of perceptual decoupling, or response strategies and motor inhibition. Participants completed a SART where they had to manually move a mouse cursor to respond to stimuli, and another SART where this extra movement was not required, as in a typical SART. Additionally, stimuli were located at either a close or a far distance away. Commission errors were inversely related to distance in the manual movement condition, as the farther distance led to longer response times which gave participants more time to inhibit prepotent responses and thus prevent commission errors. Self-reported measures of mental demand and fatigue suggested there were no differences in mental demands between the manual and automatic condition; instead the differences were primarily in physical demands. No differences were found for task-unrelated thoughts between the manual and automatic condition. The movement effect combined with participants' subjective reports are evidence for time dependent action stopping, not greater cognitive engagement. These findings support a response strategy perspective as opposed to a perceptual decoupling perspective, and have implications for authors considering using the SART. Applied implications of this research are also discussed.
The eyes are preferentially attended over other facial features and recent evidence suggests this bias is difficult to suppress. To further examine the automatic and volitional nature of this bias for eye information, we used a novel prompting face recognition paradigm in 41 adults and measured the location of their first fixations, overall dwell time and behavioural responses. First, patterns of eye gaze were measured during a free-viewing forced choice face recognition paradigm. Second, the task was repeated but with prompts to look to either the eyes or the mouth. Participants showed significantly more first fixations to the eyes than mouth, both when prompted to look at the eyes and when prompted to look at the mouth. The pattern of looking to the eyes when prompted was indistinguishable from the unprompted condition in which participants were free to look where they chose. Notably, the dwell time data demonstrated that the eye bias did not persist over the entire presentation period. Our results suggest a difficult-to-inhibit bias to initially orient to the eyes, which is superseded by volitional, top-down control of eye gaze. Further, the amount of looking to the eyes is at a maximum level spontaneously and cannot be enhanced by explicit instructions.
Eye vergence is the slow movement of both eyes in opposite directions enabling binocular vision. Recently, it was suggested that vergence could be involved in orienting visual attention and memory having a role in cognitive processing of sensory information. In the present study, we assessed whether such vergence responses are observed in early childhood. We measured eye vergence responses in 43 children (12–37 months of age) while looking at novel and repeated object images. Based on previous research, we hypothesized that visual attention and Visual Short-Term Memory (VSMT) would be evidenced by differential vergence responses for both experimental conditions, i.e. repeated (familiar) vs. novel items. The results show that attention related vergence is present in early childhood and that responses to repeated images differ from the ones to novel items. Our current findings suggest that vergence mechanisms could be linking visual attention with short-term memory recognition.
When someone is watching you, you may change your behaviour in various ways: this is called the ‘audience effect’. Social behaviours such as acting prosocially or changing gaze patterns may be used as signals of reputation and thus may be particularly prone to audience effects. The present paper aims to test the relationship between prosocial choices, gaze patterns and the feeling of being watched within a novel ecologically valid paradigm, where participants communicate with a video-clip of a confederate and believe she is (or is not) a live feed of a confederate who can see them back. Results show that when participants believe they are watched, they tend to make more prosocial choices and they gaze less to the confederate. We also find that the increase in prosocial behaviour when being watched correlates with social anxiety traits. Moreover, we show for the first time that prosocial choices influence subsequent gaze patterns of participants, although this is true for both live and pre-recorded interactions. Overall, these findings suggest that the opportunity to signal a good reputation to other people is a key modulator of prosocial decisions and eye gaze in live communicative contexts. They further indicate that gaze should be considered as an interactive and dynamic signal.
Earlier studies suggest that word length is influenced by the linguistic context to be precise and concise at the same time. The present study investigates whether the referential-situational context can also have an effect on the expected length of words. To test this assumption a salient property of the situational context, that is, the frequency of the unfamiliar referents was varied. The participants watched pictures of novel objects in the observational phase, presented either frequently or rarely. In the test phase they saw the same pictures of objects one by one and were asked to select one of two unfamiliar labels, which – according to them – could be the name of the object displayed. The two labels provided for each object at test had either short or long orthographic length. It was hypothesized that participants will select the long label more frequently when they had to guess the name of rare objects in contrast to frequent ones. The findings supported this hypothesis. Rare objects were paired with long labels significantly more often than frequent objects, resulting in a significant difference also when contrasted to chance-level. The results were similar if abbreviated or completely different label pairs were presented to the participants in the test phase suggesting that the situational context is taken into account when language users infer word form.
Previous research has indicated that Inhibition of return (IOR)supports visual search by discouraging the re-inspection of recently inspected items during search. However, it is not clear whether IOR persists after a search is completed or whether this depends on the presence of a further search in the same display. To investigate this issue, we had participants search consecutively twice in the same display (Experiment 1). Immediately after the end of the first search and after the end of the second search we probed an item which had been recently inspected or not in the previous search. The results showed that IOR as measured by the saccadic latency to the probed items was absent after the end of each of the two successive searches. In Experiment 2, we measured both saccadic latencies and manual responses in a single-search paradigm. We found that IOR during and after the search was present for saccadic responses but absent for manual responses. This suggests that IOR during and after a visual search depends on the modality of the response and the number of required searches.
Reaching the goal of control, elimination and eradication of the Neglected Tropical Disease in a foreseeable future provides significant challenges at the ground level especially regarding helminthiasis. Helminths are still mainly diagnoses by egg identification in stool, methods with low sensitivity and for most species low specificity. Cross-sectoral collaboration with regard to zoonoses is almost non-existing and cross-validation by inter-laboratory evaluation of diagnostic tests is not a common practice. The aim of this review was to elucidate the dilemma of helminth diagnosis using zoonotic trematodes as examples. Much progress has been made improving the diagnostic sensitivity of Opisthorchis and Clonorchis using DNA-based techniques but the specificity of these tests is still a challenge due to the many most common but neglected intestinal trematodes. The burden of these diseases and ways to control them remains to be elucidated. Although efficacious drugs are available, the effectiveness of mass drug administration remains to be assessed. The importance of animal reservoirs and ways to control the diseases in animals are yet unknown. Diagnostic challenges regarding Schistosoma japonicum and Schistosoma mekongi include the many light infections and the persisting influx from the animal reservoirs. The sensitivity of the faecal based techniques suited morbidity control but will be insufficient for elimination of the helminths. More accurate diagnostic tools are required and new algorithms for detection and progression of helminth elimination will be needed. Standardized inter-laboratory test validation, inter-sectoral collaboration and establishment of an international One Health diagnostic platform, sharing best practices on diagnosis of helminth zoonoses, could all significantly contribute to control and elimination of these diseases.
The objective of the investigation was to characterise infectious bursal disease viruses (IBDV) circulating in commercial and breeding poultry farms in Ethiopia between 2009 and 2011. The nucleotide and deduced amino acid sequence for VP2 hypervariable region of ten IBDVs were determined by RT-PCR, sequenced and compared to well characterised IBDV isolates worldwide. IBDV genetic material was amplified directly from bursa or cell passaged material. Phylogenetically, Ethiopian IBDVs represented two genetic lineages: very virulent (vv) IBDVs or variants of the classical attenuated vaccine strain (D78). The nucleotide identity between Ethiopian vvIBDVs ranged between 0% and 2.6%. Ethiopian vvIBDVs are clustered phylogenetically with the African IBDV genetic lineage, independent of the Asian/European lineage. This report demonstrates the circulation of vvIBDV in commercial and breeding poultry farms in Ethiopia. © 2013 Elsevier B.V.
Copepod Mesocyclops as biological control agents for dengue was previously proven to be effective and sustainable in the Northern and Central provinces of Vietnam. We aim to study social sustainability of Mesocyclops intervention in south Vietnam. Both quantitative and qualitative approaches were used. An entomological survey was carried out in 100 random households of Chanh An commune, Vinh Long Province. Aedes larval indices and Mesocyclops prevalence were compared with historical pre- and post-intervention values. In the same commune, using purposeful sampling, sixteen semi-structured interviews (1 villager leader, 1 local doctor, 10 villagers, 2 teachers, 2 entomology officials), and a focus group discussion (6 Mesocyclops program collaborators) explored water storage habits, beliefs about dengue prevention and behaviour related to Mesocyclops. Thematic analysis was conducted to interpret the qualitative findings. Aedes abundance increased after responsibility for Mesocyclops intervention moved from government to community in 2010, with post-transfer surges in Breteau Index, Container Index, and Larval Density Index. Larval increments coincided with decrease in Mesocyclops prevalence. Villagers had some knowledge of dengue but it was conflated with other mosquito borne diseases and understanding of Mesocyclops was incomplete. Program adoption among the villagers was limited. With reduced government support program collaborators reported limited capacity to conduct population monitoring, and instead targeted 'problem' households. Although the Mesocyclops program was highly sustainable in northern and central provinces of Vietnam, the intervention has not been consistently adopted by southern households in Chanh An commune. Limited education, household monitoring and government support are affecting sustainability. Findings were based on a small household sample visited over a short time period, so other evaluations are needed. However, our results suggest that government support for the Mesocyclops program is still required in this part of Vietnam.
With support from the Global Fund, the United States President's Malaria Initiative (PMI) and other cooperating partners, Malawi is implementing a comprehensive malaria control programme involving indoor residual spraying in targeted districts, universal coverage with insecticide-treated bed nets, use of rapid diagnostic tests to confirm the clinical diagnosis of malaria and use of the highly effective artemisinin-based combination therapy, artemether-lumefantrine (AL), as the first-line treatment for malaria. We genotyped 24 genome-wide single nucleotide polymorphisms (SNPs) in Plasmodium falciparum infections (n=316) sampled from a single location in Malawi before (2006 and 2007) and after enhanced intervention (2008 and 2012). The SNP data generated were used to examine temporal changes in the proportion of multiple-genotype infections (MIs), mean number of heterozygous SNPs within MIs, parasite genetic diversity (expected heterozygosity and genotypic richness), multilocus linkage disequilibrium and effective population size (Ne). While the proportion of MIs, expected heterozygosity, genotypic richness, multilocus linkage disequilibrium and Ne were unchanged over time, the mean number (±standard deviation) of heterozygous SNPs within MIs decreased significantly (p=0.01) from 9(±1) in 2006 to 7(±1) in 2012. These findings indicate that the genetic diversity of P. falciparum malaria parasites in this area remains high, suggesting that only subtle gains, if any, have been made in reducing malaria transmission. Continued surveillance is required to evaluate the impact of malaria control interventions in this area and the rest of Malawi, and to better target control interventions.
The Xinjiang Uyghur Autonomous Region in northwest China is one of the world's most important foci for cystic echinococcosis. Domestic dogs are the main source for human infection, and previous studies in Xinjiang have found a canine Echinococcus spp. coproELISA prevalence of between 36% and 41%. In 2010 the Chinese National Echinococcosis Control Programme was implemented in Xinjiang, and includes regular dosing of domestic dogs with praziquantel. Six communities in Hobukesar County, northwest Xinjiang were assessed in relation to the impact of this control programme through dog necropsies, dog Echinococcus spp. coproantigen surveys based on Lot Quality Assurance Sampling (LQAS) and dog owner questionnaires. We found that 42.1% of necropsied dogs were infected with Echinococcus granulosus, and coproELISA prevalences were between 15% and 70% in the communities. Although approximately half of all dog owners reported dosing their dogs within the 12 months prior to sampling, coproELISA prevalence remained high. Regular praziquantel dosing of owned dogs in remote and semi-nomadic communities such as those in Hobukesar County is logistically very difficult and additional measures should be considered to reduce canine echinococcosis.
Many eukaryotic pathogenic microorganisms that were previously assumed to propagate clonally have retained cryptic sexual cycles. The principal reproductive mode of Trypanosoma cruzi, the aetiological agent of Chagas disease, remains a controversial topic. Despite the existence of two recent natural hybrid lineages, a pervasive view is that recombination has been restrained at an evolutionary scale and is of little epidemiological relevance to contemporary parasite populations. This article reviews the growing number of field studies which indicate that natural hybridization in T. cruzi may be frequent,non-obligatory and idiosyncratic; potentially involving independent exchange of kinetoplast and nuclear genetic material as well as canonical meiotic mechanisms. Together these observations now challenge the traditional paradigm of preponderate clonal evolution in T. cruzi and highlight the need for additional ,intensive and appropriately sampled field surveys, complemented by high resolution, combined nuclear and mitochondrial population genetics analyses.
This review reports on laboratory diagnostic approaches for selected, highly pathogenic neglected zoonotic diseases, i.e. anthrax, bovine tuberculosis, brucellosis, echinococcosis, leishmaniasis, rabies, Taenia solium-associated diseases (neuro-/cysticercosis & taeniasis) and trypanosomiasis. Diagnostic options, including microscopy, culture, matrix-assisted laser-desorption-ionisation time-of-flight mass spectrometry, molecular approaches and serology are introduced. These procedures are critically discussed regarding their diagnostic reliability and state of evaluation. For rare diseases reliable evaluation data are scarce due to the rarity of samples. If bio-safety level 3 is required for cultural growth, but such high standards of laboratory infrastructure are not available, serological and molecular approaches from inactivated sample material might be alternatives. Multiple subsequent testing using various test platforms in a stepwise approach may improve sensitivity and specificity. Cheap and easy to use tests, usually called “rapid diagnostic tests” (RDTs) may impact disease control measures, but should not preclude developing countries from state of the art diagnostics.
Current passive surveillance data for canine rabies, particularly for the regions where the burden is highest, are inadequate for appropriate decision making on control efforts. Poor enforcement of existing legislation and poor implementation of international guidance reduce the effectiveness of surveillance systems, but another set of problems relates to the fact that canine rabies is an untreatable condition which affects very poor sectors of society. This results in an unknown, but potentially large proportion of rabies victims dying outside the health system, deaths that are unlikely to be recorded by surveillance systems based on health center records. This article critically evaluates the potential sources of information on the number of human deaths attributable to canine rabies, and how we might improve the estimates required to move towards the goal of global canine rabies elimination.
Culex pipiens pallens and Cx. p. quinquefasciatus are important vectors of many diseases, such as West Nile fever and lymphatic filariasis. The widespread use of insecticides to control these disease vectors and other insect pests has led to insecticide resistance becoming common in these species. In this study, high throughout Illumina sequencing was used to identify hundreds of Cx. p. pallens and Cx. p. quinquefasciatus genes that were differentially expressed in response to insecticide exposure. The identification of these genes is a vital first step for more detailed investigation of the molecular mechanisms involved in insecticide resistance in Culex mosquitoes.
Background Taenia solium infections are mostly endemic in less developed countries where poor hygiene conditions and free-range pig management favor their transmission. Knowledge on patterns of infections in both human and pig is crucial to design effective control strategies. The aim of this study was to assess the prevalence, risk factors and spatial distribution of taeniasis in a rural area of the Democratic Republic of Congo (DRC), in the prospect of upcoming control activities. Methods A cross-sectional study was conducted in 24 villages of the health zone of Kimpese, Bas Congo Province. Individual and household characteristics, including geographical coordinates were recorded. Stool samples were collected from willing participants and analyzed using the copro-antigen enzyme-linked immunosorbent assay (copro-Ag ELISA) for the detection of taeniasis. Blood samples were collected from pigs and analyzed using the B158/B60 monoclonal antibody-based antigen ELISA (sero-Ag ELISA) to detect porcine cysticercosis. Logistic regression and multilevel analysis were applied to identify risk factors. Global clustering and spatial correlation of taeniasis and porcine cysticercosis were assessed using K functions. Local clusters of both infections were identified using the Kulldorff's scan statistic. Results A total of 4751 participants above 5 years of age (median: 23 years; IQR: 11–41) were included. The overall proportion of taeniasis positivity was 23.4% (95% CI: 22.2–24.6), ranging from 1 to 60% between villages, with a significant between-household variance of 2.43 (SE = 0.29, p < 0.05). Taeniasis was significantly associated with age (p < 0.05) and the highest positivity was found in the 5–10 years age group (27.0% (95% CI: 24.4–29.7)). Overall, 45.6% (95% CI: 40.2–51) of sampled pigs were sero-positive. The K functions revealed a significant overall clustering of human and pig infections but no spatial dependence between them. Two significant clusters of taeniasis (p<0.001; n = 276 and n = 9) and one cluster of porcine cysticercosis (p<0.001; n = 24) were found. Conclusion This study confirms high endemicity and geographical dispersal of taeniasis in the study area. The role of age in taeniasis patterns and significant spatial clusters of both taeniasis and porcine cysticercosis were evidenced, though no spatial correlation was found between human and pig infections. Urgent control activities are needed for this endemic area.
Visceral leishmaniasis (VL), one of the most important neglected tropical diseases, is caused by Leishmania donovani eukaryotic protozoan parasite of the genus Leishmania, the disease is prevalent mainly in the Indian sub-continent, East Africa and Brazil. VL can be diagnosed by PCR amplifying ITS1 and/or kDNA genes. The current study involved the optimization of Loop-mediated isothermal amplification (LAMP) for the detection of Leishmania DNA in human blood or tissue samples. Three LAMP systems were developed; in two of those the primers were designed based on shared regions of the ITS1 gene among different Leishmania species, while the primers for the third LAMP system were derived from a newly identified repeated region in the Leishmania genome. The LAMP tests were shown to be sufficiently sensitive to detect 0.1 pg of DNA from most Leishmania species. The green nucleic acid stain SYTO16, was used here for the first time to allow real-time monitoring of LAMP amplification. The advantage of real time-LAMP using SYTO 16 over end-point LAMP product detection is discussed. The efficacy of the real time-LAMP tests for detecting Leishmania DNA in dried blood samples from volunteers living in endemic areas, was compared with that of qRT-kDNA PCR.
Close to 69,000 humans die of rabies each year, most of them in Africa and Asia. Clinical rabies can be prevented by post-exposure prophylaxis (PEP). However, PEP is commonly not available or not affordable in developing countries. Another strategy besides treating exposed humans is the vaccination of vector species. In developing countries, the main vector is the domestic dog, that, once infected, is a serious threat to humans. After a successful mass vaccination of 70% of the dogs in N'Djaména, we report here a cost-estimate for a national rabies elimination campaign for Chad. In a cross-sectional survey in four rural zones, we established the canine : human ratio at the household level. Based on human census data and the prevailing socio-cultural composition of rural zones of Chad, the total canine population was estimated at 1,205,361 dogs (95% Confidence interval 1,128,008–1,736,774 dogs). Cost data were collected from government sources and the recent canine mass vaccination campaign in N'Djaména. A Monte Carlo simulation was used for the simulation of the average cost and its variability, using probability distributions for dog numbers and cost items. Assuming the vaccination of 100 dogs on average per vaccination post and a duration of one year, the total cost for the vaccination of the national Chadian canine population is estimated at 2,716,359 Euros (95% CI 2,417,353–3,035,081) for one vaccination round. A development impact bond (DIB) organizational structure and cash flow scenario were then developed for the elimination of canine rabies in Chad. Cumulative discounted cost of 28.3 million Euros over ten years would be shared between the government of Chad, private investors and institutional donors as outcome funders. In this way, the risk of the investment could be shared and the necessary investment could be made available upfront – a key element for the elimination of canine rabies in Chad.
Brazil reported the majority of the dengue cases in Americas during the last two decades, where the occurrence of human dengue cases is exclusively attributed to the Aedes (Stegomyia) aegypti (Linnaeus). Nowadays, other recognized Dengue virus (DENV) vector in Asian countries, Aedes (Stegomyia) albopictus (Skuse), has been detected in more than half of the 5565 Brazilian municipalities. Therefore, the aim of the present study was to investigate the presence of, and determine the Ae. albopictus’ dynamics influenced by spatiotemporal characteristics in a dengue-endemic risk city of Belo Horizonte, Minas Gerais State's capital. Aedes albopictus were collected across four consecutive DENV transmission seasons from 2010 to 2014. These mosquitoes were caught in three selected districts, which had been reported in the previous ten years as having high mosquito densities and an elevated concentration of human dengue cases during epidemic seasons. All field-caught Ae. albopictus was individually processed by real-time RT-PCR, to research the DENV presence. The third season (p < 0.05) and the Pampulha district (p < 0.05) had the highest proportions of field-caught Ae. albopictus, respectively. The second season had the highest proportion of DENV-infected field-caught females (p < 0.05), but there was no difference among the proportions of DENV-infected Ae. albopictus when comparing the collection in the three districts (p = 0.98). Minimum (p = 0.004) and maximum (p < 0.0001) temperature were correlated with the field-caught Ae. albopictus in four different periods and districts. In the generalized linear model of Poisson, the field-caught DENV-infected Ae. albopictus (p = 0.005), East district (p = 0.003), minimum temperature (p < 0.0001) and relative humidity (p = 0.001) remained associated with the total number of human dengue cases. Our study demonstrated that the number of field-caught DENV-infected Ae. albopictus was inversed correlated with the number of human dengue cases. Our study raises the possibility that the DENV circulating in mosquitoes Ae. albopictus is happening in non-epidemic periods, showing that this species may be keeping only the presence of the virus in nature. Further long-term studies are necessary to better understand the role of Ae. albopictus in DENV transmission and or its vectorial competence in Belo Horizonte and in other endemic cities in Brazil and in the New World countries.
In Zanzibar, United Republic of Tanzania, Madrassa schools are influential institutions, where children and adults can learn about the interpretation of the Koran. We aimed to explore the involvement of Madrassa teachers for behavior change interventions in a randomized operational research trial designed to investigate the impact of multiple approaches to eliminate urogenital schistosomiasis transmission from Zanzibar. Madrassa teachers performing in the 30 communities of the behavior change study arm were trained in new interactive and participatory teaching methods by the local behavioral team and provided with schistosomiasis-teaching tools for teaching about transmission and prevention in their Madrassa. In July 2014, in a qualitative research study, we conducted 25 semi-structured interviews with Madrassa teachers to find out how they perceived their involvement in interventions against schistosomiasis. In 2014, 5926 among the 8497 registered Madrassa students in 30 communities on Unguja and Pemba islands received health education and participated in interactive behavior change exercises about schistosomiasis. Madrassa teachers reported that they valued their inclusion in the study and the opportunity to educate their students about schistosomiasis transmission, prevention, and treatment. They also perceived personal and community benefits as a result of their training and strongly supported the inclusion of additional Madrassa teachers in future intervention activities. Madrassa teachers are influential in the Zanzibari society, and hence are important change agents within our community-level behavioral intervention. They might constitute an untapped resource that can help to expand and increase acceptance of and participation in schistosomiasis and other neglected tropical disease control activities in African Muslim communities.
It is estimated that over a billion people are infected with soil-transmitted helminths (STHs) globally with majority occurring in tropical and subtropical regions of the world. The roundworm (Ascaris lumbricoides), whipworm (Trichuris trichiura), and hookworms (Ancylostoma duodenale and Necator americanus) are the main species infecting people. These infections are mostly gained through exposure to faecally contaminated water, soil or contaminated food and with an increase in the risk of infections due to wastewater and sludge reuse in agriculture. Different methods have been developed for the detection and quantification of STHs eggs in environmental samples. However, there is a lack of a universally accepted technique which creates a challenge for comparative assessments of helminths egg concentrations both in different samples matrices as well as between locations. This review presents a comparison of reported methodologies for the detection of STHs eggs, an assessment of the relative performance of available detection methods and a discussion of new emerging techniques that could be applied for detection and quantification. It is based on a literature search using PubMed and Science Direct considering all geographical locations. Original research articles were selected based on their methodology and results sections. Methods reported in these articles were grouped into conventional, molecular and emerging techniques, the main steps in each method were then compared and discussed. The inclusion of a dissociation step aimed at detaching helminth eggs from particulate matter was found to improve the recovery of eggs. Additionally the selection and application of flotation solutions that take into account the relative densities of the eggs of different species of STHs also results in higher egg recovery. Generally the use of conventional methods was shown to be laborious and time consuming and prone to human error. The alternate use of nucleic acid-based techniques has improved the sensitivity of detection and made species specific identification possible. However, these nucleic acid based methods are expensive and less suitable in regions with limited resources and skill. The loop mediated isothermal amplification method shows promise for application in these settings due to its simplicity and use of basic equipment. In addition, the development of imaging soft-ware for the detection and quantification of STHs shows promise to further reduce human error associated with the analysis of environmental samples. It may be concluded that there is a need to comparatively assess the performance of different methods to determine their applicability in different settings as well as for use with different sample matrices (wastewater, sludge, compost, soil, vegetables etc.).
Insecticide-treated nets are currently a major tool to reduce malaria transmission. Their level of repellency affects contact of the mosquito with the net, but may also influence the mosquito's entry into the house. The response of host-seeking malaria mosquitoes approaching the eave of an experimental house was recorded within a large screen house. We compared entry- and exit rates in relation to the presence in the house of different insecticide-treated bed nets (ITNs) with an untreated net. Mosquitoes were lured towards the house by dispensing a synthetic host-odour blend from within the net in the house. Complementary WHO bioassays revealed that the treated nets caused high knock-down- and mortality responses to the Anopheles gambiae sensu stricto strain tested. The proportion of mosquitoes that came into view of the cameras and subsequently entered the house did not differ between treated nets and the untreated net. Treated nets did not affect proportions of mosquitoes that exited the house and departed from view around the eave. However, the percentage of house-leaving and re-entering mosquitoes when an insecticide- treated net was present, was lower than in the presence of an untreated net. Our results indicated that there was no spatial repellent effect from pyrethroid-treated nets that influences house-entry at eave level. It is argued that the toxic effect of treated bed nets resulted in a reduced number of mosquitoes re-entering the house, which could thereby affect malaria transmission in neighbouring, unprotected houses.
Globally, malaria remains one of the most important vector-borne diseases despite the extensive use of vector control, including indoor residual spraying (IRS) and insecticide-treated nets (ITNs). These control methods target endophagic vectors, whereas some malaria vectors, such as Anopheles arabiensis, preferentially feed outdoors on cattle, making it a complicated vector to control using conventional strategies. Our study evaluated whether treating cattle with a capsule containing the active ingredient (AI) fipronil could reduce vector density and sporozoite rates, and alter blood feeding behavior, when applied in a small-scale field study. A pilot field study was carried out in the Samia District, Western Kenya, from May to July 2015. Four plots, each comprised of 50 huts used for sleeping, were randomly designated to serve as control or treatment. A week before cattle treatment, baseline mosquito collections were performed inside the houses using mechanical aspirators. Animals in the treatment (and buffer) were administered a single oral application of fipronil at ∼0.5 mg/kg of body weight. Indoor mosquito collections were performed once a week for four weeks following treatment. Female mosquitoes were first identified morphologically to species complex, followed by PCR-based methods to obtain species identity, sporozoite presence, and the host source of the blood meal. All three species of anophelines found in the study area (An. gambiae s.s., An. arabiensis, An. funestus s.s.) were actively transmitting Plasmodium falciparum during the study period. The indoor resting density of An. arabiensis was significantly reduced in treatment plot one at three weeks post-treatment (T1) (efficacy = 89%; T1 density = 0.08, 95% credibility intervals [0.05, 0.10]; control plot density = 0.78 [0.22, 0.29]) and at four weeks post-treatment (efficacy = 64%; T1 density = 0.16 [0.08, 0.14]; control plot density = 0.48 [0.17, 0.22]). The reduction of An. arabiensis mosquitoes captured in the treatment plot two was higher: zero females were collected after treatment. The indoor resting density of An. gambiae s.s. was not significantly different between the treatment (T1, T2) and their corresponding control plots (C1, C2). An. funestus s.s. showed an increase in density over time. The results of this preliminary study suggest that treating cattle orally with fipronil, to target exophagic and zoophagic malaria vectors, could be a valuable control strategy to supplement existing vector control interventions which target endophilic anthropophilic species.
Background The Leishmaniases are caused by the protozoan parasites of the genus Leishmania and are transmitted to humans by the bite of infected female phlebotomine sand flies. Both visceral and cutaneous leishmaniases are widely distributed in different parts of Ethiopia. The aim of this study was to determine the diversity and altitudinal distribution of phlebotomine sand flies from Kafta Humera to Gondar town in northwest Ethiopia. Methods Seven localities were selected with distinct altitudinal variations between 550 m above sea level (m a.s.l) and 2300 m a.s.l. In each locality, sand flies were collected using standard CDC light traps and sticky traps during the active sand fly season from December 2012 to May 2013. Shannon-Weiner species diversity index and Jaccard's coefficient were used to estimate species diversity and similarity between altitudes and localities, respectively. Results A total of 89,044 sand flies (41,798 males and 47, 246 females) were collected from the seven localities/towns throughout the study period. Twenty-two species belonging to 11 species in the genus Phlebotomus and 11 species in the genus Sergentomyia were documented. Of these, Sergentomyia clydei (25.87%), S. schwetzi (25.21%), S. africana (24.65%), S. bedfordi (8.89%), Phlebotomus orientalis (6.43%), and S. antennata (4.8%) were the most prevalent species. The remaining 10 Phlebotomus species and six Sergentomyia were less frequent catches. In CDC light trap and sticky trap, higher species diversity and richness for both male and female sand flies was observed at low altitude ranging from 550 to 699 m a.s.l in Adebay village in Kafta Humera district whereas low species richness and high evenness of both sexes were also observed in an altitude 1950–2300 m a.s.l. Conclusion The results revealed that the presence of leishmaniasis vectors such as P. orientalis, P. longipes, P. papatasi, and P. duboscqi in different altitudes in northwest Ethiopia. P. orientalis a vector of L. donovani, occurred between altitude 500–1100 m a.s.l, the area could be at high risk of VL. P. longipes a vector of L. aethiopica, was recorded in the highland area in Tikil-Dingay and Gondar town, implicating the possibility of CL transmission. Hence, further investigation into vector competence in relation to leishmaniasis (VL and CL) in the region is very vital.
Consumption of traditional fermented dairy products (tFDP) in Africa leads to the ingestion of up to 108 Streptococcus infantarius subspecies infantarius (Sii) per millilitre of spontaneously fermented milk. Sii is a member of the Streptococcus bovis/Streptococcus equinus complex (SBSEC) for which some members are associated particularly with colorectal cancer or endocarditis. The extent of health risks to tFDP consumers is largely unknown. A hospital-based unmatched case-control study was conducted at Kenyatta National Hospital, Nairobi (Kenya) on 80 cases and 193 controls that were selected exhaustively from patients attending colonoscopy at the hospital. Logistic regression models adjusted for age, sex and residency were used in the statistical analysis. Consumption of tFDP was not associated with CRC (odds ratio (OR) 1.4; 95% Confidence interval (CI) 0.7–2.7; p = 0.34). Risk factors associated with CRC included age above 40 years, and consumption of processed meat and alcohol. Faecal carriage of Sii was significantly higher in persons with colon tumours and polyps compared to controls (8.4% vs 21.6%: OR: 4.6; CI 1.3–15.9). Patients with haemorrhoids represented an unexpected carrier group with significantly higher Sii faecal carriage (30.4%, CI: 17.7–45.8). Consumption of tFDP does not represent risk factors for CRC whereas Sii seems to be associated with CRC. However, there is urgent need to assess this finding also in the general population, investigate the causality of SBSEC, Sii and CRC as well as compare the phylogenetic, functional and genomic relationship between human and dairy Sii with regards to the ongoing application of Sii in FDP production.
Neurocysticercosis is a major cause of epilepsy in countries where Taenia solium is endemic and the parasite is a major cause of food-borne disease globally. Pigs are the natural intermediate host involved in transmission of the parasite. T. solium is known to be endemic in Nepal, however there is limited reliable data about the prevalence of the disease in Nepal. The aim of this study was to determine accurately the prevalence of porcine cysticercosis in slaughter age pigs in an area of Nepal where pigs are known to be free-roaming. Pigs were obtained from the Udaypur Village Development Committee (VDC) and Hirminiya & Betahani VDC of the Banke district in Nepal. One hundred and ten animals of slaughter age (approximately 8–16 months old) were purchased, slaughtered and the heart, liver, brain and half the body skeletal musculature were sliced using hand knives and the number and viability of T. solium cysts determined. Thirty two of the 110 animals were found to harbour T. solium cysticerci (29%), of which 30 (27%) were found to have viable cysticerci (93% of the infected animals). This is one of the highest prevalences of porcine cysticercosis that has been reported to date from the results of necropsy on randomly selected animals. This study highlights a high rate of transmission of T. solium in the Banke District of Nepal. It encourages further investigation of human and porcine cysticercosis in Nepal, as well as implementation of efforts to reduce transmission of the parasite and the associated human disease.
Currently, leprosy control relies on the clinical diagnosis of leprosy and the subsequent administration of multidrug therapy (MDT). However, many health workers are not familiar with the cardinal signs of leprosy, particularly in low-endemic settings including Cambodia. In response, a new approach to early diagnosis was developed in the country, namely retrospective active case finding (RACF) through small mobile teams. In the frame of RACF, previously diagnosed leprosy patients are traced and their contacts screened through “drives”. According to the available records, 984 of the 1,463 (67.3%) index patients diagnosed between 2001 and 2010 and registered in the national leprosy database were successfully traced in the period 2012–2015. Migration (8.4%), death (6.7%), operational issues (1.6%) and unidentified other issues (16.0%) were the main reasons for non-traceability. A total of 17,134 contacts of traced index patients (average: 2.2 household members and 15.2 neighbors) and another 7,469 contacts of the untraced index patients could be screened. Among them, 264 new leprosy patients were diagnosed. In the same period, 1,097 patients were diagnosed through the routine passive case detection system. No change was observed in the relation between the rate at which new patients were identified and the number of years since the diagnosis of the index patient. Similar to leprosy patients diagnosed through passive case detection, the leprosy patients detected through RACF were predominantly adult males. However, the fraction of PB leprosy patients was higher among the patients diagnosed through RACF, suggesting relatively earlier diagnosis. It appears that RACF is a feasible option and effective in detecting new leprosy patients among contacts of previously registered patients. However, a well-maintained national leprosy database is essential for successful contact tracing. Hence, passive case detection in the frame of routine leprosy surveillance is a precondition for efficient RACF as the two systems are mutually enhancing. Together, the two approaches may offer an interesting option for countries with low numbers of leprosy patients but evidence of ongoing transmission. The impact on leprosy transmission could be further increased by the administration of single dose rifampicin as post-exposure prophylaxis to eligible contacts.
To date, the Republic of Rwanda has not systematically reported on distribution, diversity and malaria infectivity rate of mosquito species throughout the country. Therefore, we assessed the spatial and temporal variation of mosquitoes in the domestic environment, as well as the nocturnal biting behavior and infection patterns of the main malaria vectors in Rwanda. For this purpose, mosquitoes were collected monthly from 2010 to 2013 by human landing catches (HLC) and pyrethrum spray collections (PSC) in seven sentinel sites. Mosquitoes were identified using morphological characteristics and PCR. Plasmodium falciparum sporozoite infection rates were determined using ELISA. A total of 340,684 mosquitoes was collected by HLC and 73.8% were morphologically identified as culicines and 26.2% as anophelines. Of the latter, 94.3% were Anopheles gambiae s.l., 0.4% Anopheles funestus and 5.3% other Anopheles species. Of An. gambiae s.l., An. arabiensis and An. gambiae s.s. represented 84.4% and 15.6%, respectively. Of all An. gambiae s.l. collected indoor and outdoor, the proportion collected indoors was 51.3% in 2010 and 44.9% in 2013. A total of 17,022 mosquitoes was collected by PSC of which 20.5% were An. gambiae s.l. and 79.5% were culicines. For the seven sentinel sites, the mean indoor density for An. gambiae s.l. varied from 0.0 to 1.0 mosquitoes/house/night. P. falciparum infection rates in mosquitoes varied from 0.87 to 4.06%. The entomological inoculation rate (EIR) ranged from 1.0 to 329.8 with an annual average of 99.5 infective bites/person/year. This longitudinal study shows, for the first time, the abundance, species composition, and entomological inoculation rate of malaria mosquitoes collected throughout Rwanda.
Currently, the national malaria control programme (NMCP) of Sierra Leone recommends artesunate–amodiaquine (ASAQ) and artemether–lumefantrine (AL) as first- and second-line treatment for uncomplicated malaria, respectively, and artesunate + sulfadoxine–pyrimethamine (SP) for intermittent preventive treatment during pregnancy and for infants. In 2016, the NMCP conducted a study to assess the clinical and parasitological responses of children under five years to ASAQ, AL and dihydroartemisinin–piperaquine (DHA/PPQ) according to the WHO protocol. Day-0 samples were tested for mutations in the Kelch 13 gene (pfk13) and dihydrofolate reductase/dihydropteroate synthase (pfdhfr/pfdhps) genes associated with artemisinin and SP resistance, respectively, and amplification in the pfplasmepsin2 gene for piperaquine resistance. A total of 295 (ASAQ = 128, AL = 64 and DHA/PPQ = 103) eligible children were enrolled at three sites. PCR-corrected 100% adequate clinical and parasitological response and no parasitaemia on day-3 were observed for all patients in each treatment group. Of the 278 samples with interpretable molecular data, only 2.2% carried non-synonymous pfk13 mutants (A578S, I646T), which are not associated with artemisinin resistance. None of the 103 day-0 samples from the DAH/PPQ group had pfplasmepsin2 gene amplification, confirming the absence of piperaquine resistance. The prevalence of the triple pfdhfr mutant (N51I/C59R/S108N) was close to or reached fixation (97.4–100%). For combined pfdhfr/pfdhps mutation, 55–71% carried the quadruple (N51I/C59R/S108N+A437G) mutant and about 10% the quintuple mutant N51I/C59R/S108N+A437G/K540E. Our findings confirm that ASAQ, AL and DHA/PPQ were highly effective for the treatment of uncomplicated malaria in the study areas, and neither pfk13 validated mutations nor pfplasmepsin2 multiple copies were found. The very low prevalence of the quintuple mutant in this study supports the NMCP's decision to introduce intermittent preventive treatment for infants with SP in the districts with high malaria transmission.
Background: Taenia solium is a zoonotic tapeworm widely distributed across sub-Saharan Africa. Specific health education is regarded as a central element in controlling T. solium. In 2014, an electronic health education tool called ‘The Vicious Worm’, which was concerned with prevention of T. solium was introduced to health and agricultural professionals in Mbeya, Tanzania, an endemic setting. Introduction to ´The Vicious Worm’ of 1.5 hours significantly improved the participants’ knowledge. This study revisited the same study subjects one year later to assess persistence of knowledge regarding T. solium taeniosis/cysticercosis and to assess if the health education had changed work practices for the participants and the public. Methods: The study was conducted in Tanzania between June and August 2015, with a fixed population of health and agricultural professionals recruited from a previous study testing ‘The Vicious Worm’. The study used a test, a questionnaire survey, as well as semi-structured group and individual interviews. Results: The 79 study subjects, all health or agricultural professionals, had within one year relocated from Mbeya to 16 of 21 administrative regions of Tanzania. Sixty-four agreed to participate in the test and 48 to an interview. The test showed significant improvement in knowledge regarding T. solium taeniosis/cysticercosis, compared with the baseline knowledge level of the participants. Interview data found that the participants had used ‘The Vicious Worm’ as an educational tool and applied the knowledge from the program to implement new practices consisting of by-laws and practical workshops on building latrines, pig pens and hand washing stations in their communities. Conclusion: Introduction to ‘The Vicious Worm’ led to changed practices and persistence in knowledge regarding T. solium. Incorporating health education as a specific health intervention tool should be encouraged and implemented at national or programmatic level.
Visceral Leishmaniasis (VL) is a disseminated protozoan infection caused by Leishmania donovani that affects almost half a million people annually. In Northern Ethiopia, VL is common in migrant agricultural laborers returning from the lowland sesame fields of Metema and Humera. Recent VL foci have emerged in resident rural populations near the town. In the current study, we evaluate multilevel entomological, epidemiological and ecological factors associated with infection and disease through fine-scale eco-epidemiological analyses in three villages. Satellite images showed that villages constructed in or close to vertisols, were likely to become endemic for VL. Vertisols or black-cotton soil, are characterized by high contents of smectitic clay minerals, which swell when hydrated and shrink upon desiccation, causing extensive deep cracking during the dry season. The population densities of Phlebotomus orientalis, the vector, were negatively correlated with distance from vertisols and persons living close to vertisols were more likely to be bitten by sand flies, as evidenced by sero-positivity to Ph. orientalis saliva. Apparent (albeit non-significant) clustering of VL cases and abundant asymptomatic infections close to vertisols, suggest anthroponotic transmission around houses located close to vertisols. Comparable rates of male and female volunteers, mostly under 15 years of age, were infected with L. donovani but a significantly higher proportion of males succumbed to VL indicating a physiological gender-linked male susceptibility. Our data suggest that the abundant infected persons with high parasitemias who remain asymptomatic, may serve as reservoir hosts for anthroponotic transmission inside villages. Only limited insights on the transmission dynamics of L. donovani were gained by the study of environmental factors such as presence of animals, house structure and vegetation cover.
Japanese encephalitis (JE) is a vector-borne zoonotic disease caused by the Japanese encephalitis virus (JEV). It causes encephalitis in human and horses, and may lead to reproductive failure in sows. The first human encephalitis case in Malaya (now Malaysia) was reported during World War II in a British prison in 1942. Later, encephalitis was observed among race horses in Singapore. In 1951, the first JEV was isolated from the brain of an encephalitis patient. The true storyline of JE exposure among humans and animals has not been documented in Malaysia. In some places such as Sarawak, JEV has been isolated from mosquitoes before an outbreak in 1992. JE is an epidemic in Malaysia except Sarawak. There are four major outbreaks reported in Pulau Langkawi (1974), Penang (1988), Perak and Negeri Sembilan (1998–1999), and Sarawak (1992). JE is considered endemic only in Sarawak. Initially, both adults and children were victims of JE in Malaysia, however, according to the current reports; JE infection is only lethal to children in Malaysia. This paper describes a timeline of JE cases (background of each case) from first detection to current status, vaccination programs against JE, diagnostic methods used in hospitals and factors which may contribute to the transmission of JE among humans and animals in Malaysia.
Strongyloides stercoralis is a soil-transmitted helminth with a wide distribution in tropical and subtropical areas. The diagnosis of S. stercoralisinfection can be challenging, due to the low sensitivity of microscopic examination of stool samples and coproculture. In the last decade, different in-house molecular biology techniques for S. stercoralis have been implemented. They demonstrated good accuracy, although sensitivity does not seem sufficiently high yet. Recently, a novel PCR technique has been evaluated for the detection of S. stercoralis DNA in urine. Aim of this work was to compare the sensitivity of the real-time PCR (qPCR) on feces routinely used at the Centre for Tropical Disease (CTD) of Negrar, Verona, Italy, with that of the novel based PCR on urine. As secondary objective, we evaluated a Urine Conditioning Buffer ® (Zymoresearch) with the aim of improving nucleic acid stability in urine during sample storage/transport at ambient temperatures. Patients attending the CTD and resulting positive at routine screening with serology for S. stercoralis were invited, previous written consent, to supply stool and urine samples for molecular biology. A convenience sample of 30 patients was included. The sensitivity of qPCR on feces resulted 63%, and that of based PCR on urine was 17%. In all the samples treated with the Urine Conditioning Buffer ® there was no detectable DNA. In conclusion, the sensitivity of the novel technique resulted low, and needs further implementation before being considered as a valid alternative to the validated method.
Echinostomes are a diverse group of digenetic trematodes that are globally distributed. The diversity of echinostomes in Africa remains largely unknown, particularly in analyses using molecular markers. Therefore, we were interested in the composition and host usage patterns of African echinostomes, especially those that also use schistosome transmitting snails as intermediate hosts. We collected adults and larval stages of echinostomes from 19 different localities in East Africa (1 locality in Uganda and 18 in Kenya). In this study we provide locality information, host use, museum vouchers, and genetic data for two loci (28S and nad1) from 98 samples of echinostomes from East Africa. Combining morphological features, host use information, and phylogenetic analyses we found 17 clades of echinostomes in East Africa. Four clades were found to use more than one genus of freshwater snails as their first intermediate hosts. We also determined at least partial life cycles (2 of the 3) of four clades using molecular markers. Of the 17 clades, 13 use Biomphalaria or Bulinus as a first intermediate host. The overlap in host usage creates opportunities for competition, including against human schistosomes. Thus, our study can be used as a foundation for future studies to ascertain the interactions between schistosomes and echinostomes in their respective intermediate hosts.
Chagas disease (CD) affects over six million people and is a leading cause of heart failure in the Americas. Few are able to access diagnosis and treatment for CD, resulting in a missed opportunity to prevent morbimortality. Integration of testing and treatment with the primary healthcare level is a key step in ensuring affected people receive timely antitrypansomal therapy, which increasing evidence shows can prevent chronic complications from the disease and halt congenital transmission. This article describes three collaborative projects focused on increasing access to testing and treatment for CD through primary healthcare facilities in Bolivia, Argentina, and Colombia.
Despite more than 100 years since it was firstly described Chagas disease, only two drugs are available to treat Chagas disease: Nifurtimox launched by Bayer in 1965 and benznidazole launched by Roche in 1971. Drug discovery initiatives have been looking for new compounds as an alternative to these old drugs. Although new platforms have been used with the latest technologies, a critical step on that process still relies on the in vivo model. Unfortunately, to date, available animal models have limited predictive value and there is no standardization. With the aim to better understand the role of benznidazole, the current standard of care of Chagas disease, we performed this review. We intend to analyze the influence of the experimental design of the most used animal model, the murine model, in the assessment of the efficacy endpoint.
Japanese encephalitis virus (JEV) is a single stranded positive sense RNA virus of the genus Flavivirus that belongs to family Flaviviridae and emerged as one of the most pivotal form of viral encephalitis. The virus is transmitted to humans by mosquito vector and is an etiological agent of acute zoonotic infection. In this study, we investigated distribution and density over 3-year period in central regions of Korean peninsula. We selected two cities as mosquito-collecting locations and subdivided them into five collection sites; downtown Incheon Metropolitan City as a typical urban area, and the Hwaseong-si area as a rural area. A total of 35,445 female culicine mosquitoes were collected using black light traps or BG Sentinel™ traps from March to November 2016–2018. Aedes (Ae.) vexans nipponii was the most frequently collected specimens (48.91%), followed by Culex (Cx.) pipiens (32.05%), Ochlerotatus (Och.) dorsalis (13.58%), Och. koreicus (1.68%), and Cx. tritaeniorhynchus (1.49%). In the urban area, Cx. pipiens was the predominant species (92.21%) and the other species accounted for <5% of the total mosquitoes collected. However, in the rural area, Ae. vexans nipponii had the highest population (61.90%), followed by Och. dorsalis (17.10%), Cx. tritaeniorhynchus (1.84%) and Och, koreicus (1.78%). Culicine mosquitoes were identified at the species level, placed in pools of up to 30 mosquitoes each, and screened for flavivirus RNA using the SYBR Green-based RT-PCR. Three of the assayed 1092 pools were positive for Chaoyang virus from Ae. vexans nipponii and Japanese encephalitis virus from Cx. pipiens. The maximum likelihood estimations (the estimated number of virus-positive mosquitoes/1000 mosquitoes) for Ae. vexans nipponii positive for Chaoyang virus and Cx. pipiens for Japanese encephalitis virus were 3.095 and 0.20, respectively. The results of our study demonstrate that although mosquito-borne diseases were not detected in the potential vectors, enhanced monitoring and long-term surveillance of these vector viruses are of great public health importance.
The role of malacological surveys to identify potential transmission sites for schistosomiasis control in this era of mass drug administration have received little attention. In that context, the present study was conducted to determine the abundance, identity and disease transmission potential of intermediate host snails for intestinal schistosomiasis on Ijinga Island, north-western Tanzania. A cross-sectional malacological study was conducted between February and March 2016 on Ijinga Island, Lake Victoria, north-western Tanzania. Snails were collected at points where humans are in frequent contact with water using a standardized scooping technique and have been identified using shell morphological features. The Schistosoma infection status of the collected snails was determined by using real-time Polymerase Chain Reaction (real-time PCR). A total number of 4,888 snails were putatively identified as Biomphalaria species. A random sample of 788 snails underwent molecular analyses for Schistosoma infection. Overall, 279 (35.4%) of Biomphalaria species were identified to be infected with parasites of the lateral spined S. mansoni group. The findings confirm that Biomphalaria species collected in areas with high human water contacts are infected with Schistosoma and that there is a likeliness of local risk for schistosomiasis transmission at most water contact points around Ijinga Island.
The recent progress in theoretical and experimental studies of simultaneous spreading and evaporation of liquid droplets on solid substrates is discussed for pure liquids including nanodroplets, nanosuspensions of inorganic particles (nanofluids) and surfactant solutions. Evaporation of both complete wetting and partial wetting liquids into a nonsaturated vapour atmosphere are considered. However, the main attention is paid to the case of partial wetting when the hysteresis of static contact angle takes place. In the case of complete wetting the spreading/evaporation process proceeds in two stages. A theory was suggested for this case and a good agreement with available experimental data was achieved. In the case of partial wetting the spreading/evaporation of a sessile droplet of pure liquid goes through four subsequent stages: (i) the initial stage, spreading, is relatively short (1-2 min) and therefore evaporation can be neglected during this stage; during the initial stage the contact angle reaches the value of advancing contact angle and the radius of the droplet base reaches its maximum value, (ii) the first stage of evaporation is characterised by the constant value of the radius of the droplet base; the value of the contact angle during the first stage decreases from static advancing to static receding contact angle; (iii) during the second stage of evaporation the contact angle remains constant and equal to its receding value, while the radius of the droplet base decreases; and (iv) at the third stage of evaporation both the contact angle and the radius of the droplet base decrease until the drop completely disappears. It has been shown theoretically and confirmed experimentally that during the first and second stages of evaporation the volume of droplet to power 2/3 decreases linearly with time. The universal dependence of the contact angle during the first stage and of the radius of the droplet base during the second stage on the reduced time has been derived theoretically and confirmed experimentally. The theory developed for pure liquids is applicable also to nanofluids, where a good agreement with the available experimental data has been found. However, in the case of evaporation of surfactant solutions the process deviates from the theoretical predictions for pure liquids at concentration below critical wetting concentration and is in agreement with the theoretical predictions at concentrations above it. © 2013 Elsevier B.V. All rights reserved.
Fluorosurfactants are the most effective compounds to lower the surface tension of aqueous solutions, but their wetting properties as related to low energy hydrocarbon solids are inferior to hydrocarbon trisiloxane surfactants, although the latter demonstrate higher surface tension in aqueous solutions. To explain this inconsistency available data on the adsorption of fluorosurfactants on liquid/vapour, solid/liquid and solid/vapour interfaces are discussed in comparison to those of hydrocarbon surfactants. The low free energy of adsorption of fluorosurfactants on hydrocarbon solid/water interface should be of a substantial importance for their wetting properties. © 2014 Elsevier B.V. All rights reserved.
Bacterial antibiotic resistance is becoming more widespread due to excessive use of antibiotics in healthcare and agriculture. At the same time the development of new antibiotics has effectively ground to a hold. Chemical modifications of material surfaces have poor long-term performance in preventing bacterial build-up and hence approaches for realising bactericidal action through physical surface topography have become increasingly important in recent years. The complex nature of the bacteria cell wall interactions with nanostructured surfaces represents many challenges while the design of nanostructured bactericidal surfaces is considered. Here we present a brief overview of the bactericidal behaviour of naturally occurring and bio-inspired nanostructured surfaces against different bacteria through the physico-mechanical rupture of the cell wall. Many parameters affect this process including the size, shape, density, rigidity/flexibility and surface chemistry of the surface nanotextures as well as factors such as bacteria specificity (e.g. gram positive and gram negative) and motility. Different fabrication methods for such bactericidal nanostructured surfaces are summarised.
In this review article, we discuss recent studies on drops and bubbles in Hele-Shaw cells, focusing on how scaling laws exhibit crossovers from the three-dimensional counterparts and focusing on topics in which viscosity plays an important role. By virtue of progresses in analytical theory and high-speed imaging, dynamics of drops and bubbles have actively been studied with the aid of scaling arguments. However, compared with three-dimensional problems, studies on the corresponding problems in Hele-Shaw cells are still limited. This review demonstrates that the effect of confinement in the Hele-Shaw cell introduces new physics allowing different scaling regimes to appear. For this purpose, we discuss various examples that are potentially important for industrial applications handling drops and bubbles in confined spaces by showing agreement between experiments and scaling theories. As a result, this review provides a collection of problems in hydrodynamics that may be analytically solved or that may be worth studying numerically in the near future.
The controlled patterning of polymeric surfaces at the micro- and nanoscale offers potential in the technological development of small-scale devices, particularly within the fields of photovoltaics, micro-optics and lab- and organ-on-chip, where the topological arrangement of the surface can influence a system's power generation, optical properties or biological function - such as, in the latter case, biomimicking surfaces or topological control of cellular differentiation. One of the most promising approaches in reducing manufacturing costs and complexity is by exploitation of the self-assembling properties of colloidal particles. Self-assembly techniques can be used to produce colloidal crystals onto surfaces, which can act as replicative masks, as has previously been demonstrated with colloidal lithography, or templates in mold-replication methods with resolutions dependent on particle size. Within this context, a particular emerging interest is focused on the use of self-assembled colloidal crystal surfaces in polymer replication methods such as soft lithography, hot and soft embossing and nano-imprint lithography, offering low-cost and high-resolution alternatives to conventional lithographic techniques. However, there are still challenges to overcome for this surface patterning approach to reach a manufacturing reliability and process robustness comparable to competitive technologies already available in the market, as self-assembly processes are not always 100% effective in organizing colloids within a structural pattern onto the surface. Defects often occur during template fabrication. Furthermore, issues often arise mainly at the interface between colloidal crystals and other surfaces and substrates. Particularly when utilized in high-temperature pattern replication processes, poor adhesion of colloidal particles onto the substrate results in degradation of the patterning template. These effects can render difficulties in creating stable structures with little defect that are well controlled such that a large variety of shapes can be reproduced reliably. This review presents an overview of available self-assembly methods for the creation of colloidal crystals, organized by the type of forces governing the self-assembly process: fluidic, physical, external fields, and chemical. The main focus lies on the use of spherical particles, which are favorable due to their high commercial availability and ease of synthesis. However, also shape-anisotropic particle self-assembly will be introduced, since it has recently been gaining research momentum, offering a greater flexibility in terms of patterning. Finally, an overview is provided of recent research on the fabrication of polymer nano- and microstructures by making use of colloidal self-assembled templates.
Bacterial adhesion is a main problem in many biomedical, domestic, natural and industrial environments and forms the onset of the formation of a biofilm, in which adhering bacteria grow into a multi-layered film while embedding themselves in a matrix of extracellular polymeric substances. It is usually assumed that bacterial adhesion occurs from air or by convective-diffusion from a liquid suspension, but often bacteria adhere by transmission from a bacterially contaminated donor to a receiver surface. Therewith bacterial transmission is mechanistically different from adhesion, as it involves bacterial detachment from a donor surface followed by adhesion to a receiver one. Transmission is further complicated when the donor surface is not covered with a single layer of adhering bacteria but with a multi-layered biofilm, in which case bacteria can be transmitted either by interfacial failure at the biofilm-donor surface or through cohesive failure in the biofilm. Transmission through cohesive failure in a biofilm is more common than interfacial failure. The aim of this review is to oppose surface thermodynamics and adhesion force analyses, as can both be applied towards bacterial adhesion, with their appropriate extensions towards transmission. Opposition of surface thermodynamics and adhesion force analyses, will allow to distinguish between transmission of bacteria from a donor covered with a (sub)monolayer of adhering bacteria or a multi-layered biofilm. Contact angle measurements required for surface thermodynamic analyses of transmission are of an entirely different nature than analyses of adhesion forces, usually measured through atomic force microscopy. Nevertheless, transmission probabilities based on Weibull analyses of adhesion forces between bacteria and donor and receiver surfaces, correspond with the surface thermodynamic preferences of bacteria for either the donor or receiver surface. Surfaces with low adhesion forces such as polymer-brush coated or nanostructured surfaces are thus preferable for use as non-adhesive receiver surfaces, but at the same time should be avoided for use as a donor surface. Since bacterial transmission occurs under a contact pressure between two surfaces, followed by their separation under tensile or shear pressure and ultimately detachment, this will affect biofilm structure. During the compression phase of transmission, biofilms are compacted into a more dense film. After transmission, and depending on the ability of the bacterial strain involved to produce extracellular polymeric substances, biofilm left-behind on a donor or transmitted to a receiver surface will relax to its original, pre-transmission structure owing to the viscoelasticity of the extracellular polymeric substances matrix, when present. Apart from mechanistic differences between bacterial adhesion and transmission, the low numbers of bacteria generally transmitted require careful selection of suitably sensitive enumeration methods, for which culturing and optical coherence tomography are suggested. Opposing adhesion and transmission as done in this review, not only yields a better understanding of bacterial transmission, but may stimulate researchers to more carefully consider whether an adhesion or transmission model is most appropriate in the specific area of application aimed for, rather than routinely relying on adhesion models.
Rare earth elements (REE) are critical to a wide range of technologies ranging from mobile phones to wind turbines. Processing and extraction of REE minerals from ore bodies is, however, both challenging and relatively poorly understood, as the majority of deposits contain only limited enrichment of REEs. An improved understanding of the surface properties of the minerals is important in informing and optimising their processing, in particular for separation by froth flotation. The measurement of zeta potential can be used to extract information regarding the electrical double layer, and hence surface properties of these minerals. There are over 34 REE fluorcarbonate minerals currently identified, however bastnäsite, synchysite and parisite are of most economic importance. Bastnäsite–(Ce), the most common REE fluorcarbonate, supplies over 50% of the world's REE. Previous studies of bastnäsite have showed a wide range of surface behaviour, with the iso-electric point (IEP), being measured between pH values of 4.6 and 9.3. In contrast, no values of IEP have been reported for parisite or synchysite. In this work, we review previous studies of the zeta potentials of bastnäsite to investigate the effects of different methodologies and sample preparation. In addition, measurements of zeta potentials of parisite under water, collector and supernatant conditions were conducted, the first to be reported. These results showed an iso-electric point for parisite of 5.6 under water, with a shift to a more negative zeta potential with both collector (hydroxamic and fatty acids) and supernatant conditions. The IEP with collectors and supernatant was <3.5. As zeta potential measurements in the presence of reagents and supernatants are the most rigorous way of determining the efficiency of a flotation reagent, the agreement between parisite zeta potentials obtained here and previous work on bastnäsite suggests that parisite may be processed using similar reagent schemes to bastnäsite. This is important for future processing of REE deposits, comprising of more complex REE mineralogy.
PAMAM dendrimers have been conjectured for a wide range of biomedical applications due to their tuneable physicochemical properties. However, their application has been hindered by uncertainties in their cytotoxicity, which is influenced by dendrimer generation (i.e. size and surface group density), surface chemistry, and dosage, as well as cell specificity. In this review, biomedical applications of polyamidoamine (PAMAM) dendrimers and some related cytotoxicity studies are first outlined. Alongside these in vitro experiments, lipid membranes such as supported lipid bilayers (SLBs), liposomes, and Langmuir monolayers have been used as cell membrane models to study PAMAM dendrimer-membrane interactions. Related experimental and theoretical studies are summarized, and the physical insights from these studies are discussed to shed light on the fundamental understanding of PAMAM dendrimer-cell membrane interactions. We conclude with a summary of some questions that call for further investigations.
Despite the considerable advances of molecular-thermodynamic theory of micelle growth, agreement between theory and experiment has been achieved only in isolated cases. A general theory that can provide self-consistent quantitative description of the growth of wormlike micelles in mixed surfactant solutions, including the experimentally observed high peaks in viscosity and aggregation number, is still missing. As a step toward the creation of such theory, here we consider the simplest system – nonionic wormlike surfactant micelles from polyoxyethylene alkyl ethers, CiEj. Our goal is to construct a molecular-thermodynamic model that is in agreement with the available experimental data. For this goal, we systematized data for the micelle mean mass aggregation number, from which the micelle growth parameter was determined at various temperatures. None of the available models can give a quantitative description of these data. We constructed a new model, which is based on theoretical expressions for the interfacial-tension, headgroup-steric and chain-conformation components of micelle free energy, along with appropriate expressions for the parameters of the model, including their temperature and curvature dependencies. Special attention was paid to the surfactant chain-conformation free energy, for which a new more general formula was derived. As a result, relatively simple theoretical expressions are obtained. All parameters that enter these expressions are known, which facilitates the theoretical modeling of micelle growth for various nonionic surfactants in excellent agreement with the experiment. The constructed model can serve as a basis that can be further upgraded to obtain quantitative description of micelle growth in more complicated systems, including binary and ternary mixtures of nonionic, ionic and zwitterionic surfactants, which determines the viscosity and stability of various formulations in personal-care and house-hold detergency.
Apatite subspecies depend on their halogen and hydroxyl content; chlorapatite, hydroxylapatite and fluorapatite, with additional substitution of other elements within the lattice such as rare earth elements (REE), sodium, strontium and manganese also possible. Rare earth elements are vital to green and emerging technologies, with demand set to outstrip supply. Apatite provides a possible future source of REE. Processing rare earth deposits is often complex, with surface behaviour having a significant effect on the optimization of a process flow sheet. The effect of enrichment of natural apatite and the doping of synthetic apatite on surface behaviour can be determined by measuring the zeta potential and the isoelectric point of the mineral. In this paper, we review zeta potential studies of natural and synthetic apatite to determine the effect of elemental enrichment on surface behaviour. Fifty three studies of natural apatite and forty four studies of synthetic apatite were reviewed. The isoelectric point of apatite varied from pH 1 to pH 8.7, with studies of apatite specified to be >90% pure reducing the variation to pH 3 to pH 6.5. Of the four studies of rare earth enriched apatite found, three had IEP values between pH 3 and pH 4. A study of synthetic apatite showing enrichment of between 1 and 10% by the REE europium does not affect surface behaviour. However, no studies were found that investigated the effect of common REE processing reagents on REE enriched apatite zeta potentials. Therefore, in addition to comparing previous studies we also therefore present new zeta potential measurements of apatite from a REE enriched deposit under water and common flotation collector conditions. The IEP value of this apatite under water conditions was at pH 3.6, shifting to <3.5 under both hydroxamic acid and betacol conditions. When compared to previous studies, the behaviour of REE enriched apatite under collector conditions is similar to non-REE apatite. This result could be important for future processing of apatite enriched with REE, and therefore global apatite and rare earth supply.
Human saliva, a seemingly simple aqueous fluid, is, in fact, an extraordinarily complex biocolloid that is not fully understood, despite many decades of study. Salivary lubrication is widely believed to be a signature of good oral health and is also crucial for speech, food oral processing and swallowing. However, saliva has been often neglected in food colloid research, primarily due to its high intra- to inter-individual variability and altering material properties upon collection and storage, when used as an ex vivo research material. In the last few decades, colloid scientists have attempted designing model (i.e. ‘saliva mimicking fluid’) salivary formulations to understand saliva-food colloid interactions in an in vitro set up and its contribution on microstructural aspects, lubrication properties and sensory perception. In this Review, we critically examine the current state of knowledge on bulk and interfacial properties of model saliva in comparison to real human saliva and highlight how far such model salivary formulations can match the properties of real human saliva. Many, if not most, of these model saliva formulations share similarities with real human saliva in terms of biochemical compositions, including electrolytes, pH and concentrations of salivary proteins, such as α-amylase and highly glycosylated mucins. This, together with similarities between model and real saliva in terms of surface charge, has led to significant advancement in decoding various colloidal interactions (bridging, depletion) of charged emulsion droplets and associated sensory perception in the oral phase. However, model saliva represents significant dissimilarity to real saliva in terms of lubricating properties. Based on in-depth examination of properties of mucins derived from animal sources (e.g. pig gastric mucins (PGM) or bovine submaxillary mucin (BSM)), we can recommend that BSM is currently the most optimal commercially available mucin source when attempting to replicate saliva based on surface adsorption and lubrication properties. Even though purification via dialysis or chromatographic techniques may influence various physicochemical properties of BSM, such as structure and surface adsorption, the lubricating properties of model saliva formulations based on BSM are generally superior and more reliable than the PGM counterpart at orally relevant pH. Comparison of mucin-containing model saliva with ex vivo human salivary conditioning films suggests that mucin alone cannot replicate the lubricity of real human salivary pellicle. Mucin-based multi-layers containing mucin and oppositely charged polyelectrolytes may offer promising avenues in the future for engineering biomimetic salivary pellicle, however, this has not been explored in oral tribology experiments to date. Hence, there is a strong need for systematic studies with employment of model saliva formulations containing mucins with and without polycationic additives before a consensus on a standardized model salivary formulation can be achieved. Overall, this review provides the first comprehensive framework on simulating saliva for a particular bulk or surface property when doing food oral processing experiments.
Oleosomes are natural oil droplets, abundant in plants and more specifically in seeds, composing 20–50 wt% of their mass. The structure of oleosomes is the mechanism that seeds developed to safely store energy in the form of triacylglycerols and use it during germination. For this, the phospholipid/protein membrane that covers and protects the triacylglycerols has been wisely developed during evolution to grant them extreme stability against physical and chemical stresses. The remarkable property-performance relationships of oleosomes have generated a lot of interest to incorporate them in oil-in-water emulsions and take advantage of their sophisticated membrane. However, the structure-function relationship of the molecular components in the oleosome membrane is still not well understood and requires more attention in order to take complete advantage of their potential functions. The aim of this review is to give insights into the architecture of the oleosomes and to discuss the exploitation of their properties in advanced and broad applications, from carrying and protecting sensitive molecules to bio-catalysis.
We consider the polynomial representation of Double Affine Hecke Algebras (DAHAs) and construct its submodules as ideals of functions vanishing on the special collections of affine planes. This generalizes certain results of Kasatani in types A n, (Cn∨,Cn). We obtain commutative algebras of difference operators given by the action of invariant combinations of Cherednik-Dunkl operators in the corresponding quotient modules of the polynomial representation. This gives known and new generalized Macdonald-Ruijsenaars systems. Thus in the cases of DAHAs of types A n and (Cn∨,Cn) we derive Chalykh-Sergeev-Veselov operators and a generalization of the Koornwinder operator respectively, together with complete sets of quantum integrals in the explicit form. © 2013 The Authors.
We prove that a coherent DQ-kernel induces an equivalence between the derived categories of DQ-modules with coherent cohomology if and only if the graded commutative kernel associated to it induces an equivalence between the derived categories of coherent sheaves. © 2014 The Author.
Combining known spectral sequences with a new spectral sequence relating reduced and unreduced slN-homology yields a relationship between the Homflypt-homology of a knot and its slN-concordance invariants. As an application, some of the slN-concordance invariants are shown to be linearly independent. © 2014 The Author.
We introduce a set of multi-way dual Cheeger constants and prove universal higher-order dual Cheeger inequalities for eigenvalues of normalized Laplace operators on weighted finite graphs. Our proof proposes a new spectral clustering phenomenon deduced from metrics on real projective spaces. We further extend those results to a general reversible Markov operator and find applications in characterizing its essential spectrum.
The spectrum of a selfadjoint second order elliptic differential operator in L2(Rn) is described in terms of the limiting behavior of Dirichlet-to-Neumann maps, which arise in a multi-dimensional Glazman decomposition and correspond to an interior and an exterior boundary value problem. This leads to PDE analogs of renowned facts in spectral theory of ODEs. The main results in this paper are first derived in the more abstract context of extension theory of symmetric operators and corresponding Weyl functions, and are applied to the PDE setting afterwards.
We prove that the probability of crossing a large square in quenched Voronoi percolation converges to 1/2 at criticality, confirming a conjecture of Benjamini, Kalai and Schramm from 1999. The main new tools are a quenched version of the box-crossing property for Voronoi percolation at criticality, and an Efron-Stein type bound on the variance of the probability of the crossing event in terms of the sum of the squares of the influences. As a corollary of the proof, we moreover obtain that the quenched crossing event at criticality is almost surely noise sensitive.
This article discusses invariant theories in some exterior algebras, which are closely related to Amitsur-Levitzki type theorems.First we consider the exterior algebra on the vector space of square matrices of size n, and look at the invariants under conjugations. We see that the algebra of these invariants is isomorphic to the exterior algebra on an n-dimensional vector space. Moreover we give a Cayley-Hamilton type theorem for these invariants (the anticommutative version of the Cayley-Hamilton theorem). This Cayley-Hamilton type theorem can also be regarded as a refinement of the Amitsur-Levitzki theorem.We discuss two more Amitsur-Levitzki type theorems related to invariant theories in exterior algebras. One is a famous Amitsur-Levitzki type theorem due to Kostant and Rowen, and this is related to O(V)-invariants in Λ(Λ2(V)). The other is a new Amitsur-Levitzki type theorem, and this is related to GL(V)-invariants in Λ(Λ2(V)⊕S2(V*)).
